{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fuzzy_match_score.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqkqt6nZkNXC",
        "outputId": "c3aa2341-96fa-4fe7-df78-7cf777cfe718"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vivrxm6Pzrwh"
      },
      "source": [
        "#data\r\n",
        "import pandas as pd\r\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/Data/quora duplicate identification/train.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWD6CG0wU5Xp"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "dq6dvFo0Q0qv",
        "outputId": "ed165ad7-a791-437d-deb9-bb2ff615f995"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  ...                                          question2 is_duplicate\n",
              "0   0     1  ...  What is the step by step guide to invest in sh...            0\n",
              "1   1     3  ...  What would happen if the Indian government sto...            0\n",
              "2   2     5  ...  How can Internet speed be increased by hacking...            0\n",
              "3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n",
              "4   4     9  ...            Which fish would survive in salt water?            0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aI3H9xRVoIel",
        "outputId": "2be16bbd-2ee8-4aab-a133-43695f0d5653"
      },
      "source": [
        "len(np.intersect1d(list(set(('What is the step by step guide to invest in sh...').split())),list(set(('What is the step by step guide to invest in sh...').split()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fae2pQLwTdJy",
        "outputId": "a4389b94-6053-4bea-f985-a7845d838a67"
      },
      "source": [
        "list(set(('What is the step by step guide to invest in sh...').split()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['by', 'the', 'sh...', 'step', 'to', 'is', 'What', 'guide', 'invest', 'in']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81w07FJqUJHY"
      },
      "source": [
        "x1_data=df['question1'].astype(str).values\r\n",
        "x2_data=df['question2'].astype(str).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9M2XexgzAQ8"
      },
      "source": [
        "x1_data,x2_data=[i.lower() for i in x1_data],[i.lower() for i in x2_data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cVHMrH_yQ-T"
      },
      "source": [
        "from drive.MyDrive.regex import regex_clean\r\n",
        "\r\n",
        "x1_data=[regex_clean(data) for data in x1_data]\r\n",
        "x2_data=[regex_clean(data) for data in x2_data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsMJmpTAVodx",
        "outputId": "2124d774-f06a-4014-c490-489b7782c6e0"
      },
      "source": [
        "(x1_data[0]+\" \"+x2_data[0]).split()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what',\n",
              " 'is',\n",
              " 'the',\n",
              " 'step',\n",
              " 'by',\n",
              " 'step',\n",
              " 'guide',\n",
              " 'to',\n",
              " 'invest',\n",
              " 'in',\n",
              " 'share',\n",
              " 'market',\n",
              " 'in',\n",
              " 'india',\n",
              " 'what',\n",
              " 'is',\n",
              " 'the',\n",
              " 'step',\n",
              " 'by',\n",
              " 'step',\n",
              " 'guide',\n",
              " 'to',\n",
              " 'invest',\n",
              " 'in',\n",
              " 'share',\n",
              " 'market']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "source": [
        "### Only one question pair has been tested,similarly any question pair can can be tested and score can be produced,the question pair with best fuzzy score is considered to be carried forward in the Machine learning system's pipeline  "
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrioguD4Up5C"
      },
      "source": [
        "q11,q22=[],[]\n",
        "overlap=[]\n",
        "for q1,q2 in zip(x1_data,x2_data):\n",
        "  q1=\"the verbal aptitude questions have gramatical mistakes in the question and we are asked to choose the options with gramatical mistake\" #\n",
        "  q2=\"few words missing in them, I hope these can be looked into gramatical mistakes in the question so that the next test is not so\"\n",
        "  c=np.intersect1d(list(set(q1.split())),list(set(q2.split())))\n",
        "  if len(c)==0:\n",
        "    fuzzy_ratio=0\n",
        "  else:\n",
        "    overlap.append(len(c))\n",
        "    for word in (q1+\" \"+q2).split():\n",
        "      if word not in set(q2.split()):\n",
        "        q11.append(word)\n",
        "\n",
        "      if word not in set(q1.split()):\n",
        "        q22.append(word)\n",
        "\n",
        "    rem_q11,rem_q22=[],[]\n",
        "    p_overlap=0\n",
        "    break\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdjz0ShkUbFh",
        "outputId": "d7775719-b989-4fd4-f2c4-177266ca257c"
      },
      "source": [
        "q11,q22  # for 1st question pair"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['verbal',\n",
              "  'aptitude',\n",
              "  'questions',\n",
              "  'have',\n",
              "  'and',\n",
              "  'we',\n",
              "  'are',\n",
              "  'asked',\n",
              "  'to',\n",
              "  'choose',\n",
              "  'options',\n",
              "  'with',\n",
              "  'mistake'],\n",
              " ['few',\n",
              "  'words',\n",
              "  'missing',\n",
              "  'them,',\n",
              "  'I',\n",
              "  'hope',\n",
              "  'these',\n",
              "  'can',\n",
              "  'be',\n",
              "  'looked',\n",
              "  'into',\n",
              "  'so',\n",
              "  'that',\n",
              "  'next',\n",
              "  'test',\n",
              "  'is',\n",
              "  'not',\n",
              "  'so'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yWlNf6zFSJq",
        "outputId": "f16a8881-05a8-42da-d177-d7e601606adb"
      },
      "source": [
        "!pip install python-Levenshtein"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-Levenshtein\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/dc/97f2b63ef0fa1fd78dcb7195aca577804f6b2b51e712516cc0e902a9a201/python-Levenshtein-0.12.2.tar.gz (50kB)\n",
            "\r\u001b[K     |██████▌                         | 10kB 25.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20kB 31.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 30kB 27.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 40kB 31.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-Levenshtein) (53.0.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp36-cp36m-linux_x86_64.whl size=148896 sha256=5009f2cb5ac34702bf66c3d2417adfe7c089bc3a5dee5d1789180be4abaee208\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/26/73/4b48503bac73f01cf18e52cd250947049a7f339e940c5df8fc\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein\n",
            "Successfully installed python-Levenshtein-0.12.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRSxaY0YPQdR",
        "outputId": "2fbd5c1b-cdc4-4b21-ccfb-09416dbbbd3a"
      },
      "source": [
        "# lets use google's word2vec embeddings as mentioned in the paper\r\n",
        "!mkdir ~/.kaggle\r\n",
        "!cp /content/drive/MyDrive/kaggle.json /root/.kaggle\r\n",
        "!chmod 600 /root/.kaggle/kaggle.json\r\n",
        "!kaggle datasets download alvations/vegetables-google-word2vec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading vegetables-google-word2vec.zip to /content\n",
            " 99% 1.64G/1.66G [00:17<00:00, 145MB/s]\n",
            "100% 1.66G/1.66G [00:17<00:00, 99.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jw0T1T1vQ06O",
        "outputId": "966f4405-8cea-4a74-f1d9-b5496d4f9fd6"
      },
      "source": [
        "!unzip /content/vegetables-google-word2vec.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/vegetables-google-word2vec.zip\n",
            "  inflating: word2vec.news.negative-sample.300d.npy  \n",
            "  inflating: word2vec.news.negative-sample.300d.pkl  \n",
            "  inflating: word2vec.news.negative-sample.300d.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4HRcd7aQ3uU"
      },
      "source": [
        "embedding=np.load('/content/word2vec.news.negative-sample.300d.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU7bNjX2Q4ab"
      },
      "source": [
        "vocab=[line.strip() for line in open('/content/word2vec.news.negative-sample.300d.txt')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6MkDpqJZDJ8"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9D0CNei5UbX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe2a1633-10ad-424f-d288-77e9fc48570e"
      },
      "source": [
        "cosine_similarity([embedding[vocab.index('how')]],[embedding[vocab.index('me')]]) #checking "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.28679878]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXGQ-_ITE5Tf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4c0fd8d-85db-42e4-e25b-961652f65c99"
      },
      "source": [
        "#paper has used normalized levenshtein distance and the optimum value of thres1 and thres2 were calculated after several experiments by researchers\r\n",
        "\r\n",
        "thres1,thres2=0.6,0.55\r\n",
        "\r\n",
        "from Levenshtein import distance                             \r\n",
        "\r\n",
        "for word1 in q11:\r\n",
        "  for word2 in q22:\r\n",
        "    dist= distance(word1,word2)\r\n",
        "    norm_dist=np.linalg.norm(dist)\r\n",
        "    sync_score=(1-norm_dist)\r\n",
        "    if sync_score>thres1:\r\n",
        "      print(f'syntactic similarity {word1,word2}/n')\r\n",
        "      p_overlap+=sync_score\r\n",
        "      rem_q11.append(word1)\r\n",
        "      rem_q22.append(word2)\r\n",
        "      break\r\n",
        "    elif word1 in vocab and word2 in vocab:                                 \r\n",
        "      a=embedding[vocab.index(word1)]                                       # averaging the embedding vectors will loose information about the word and just summing it up is not a soln\r\n",
        "      b=embedding[vocab.index(word2)]                                       # I have used sklearn metrics for measuring cosine similarity between two embeeding vecors of given two words\r\n",
        "      sym_score=cosine_similarity([a],[b])\r\n",
        "      if sym_score>thres2:\r\n",
        "        p_overlap+=sym_score\r\n",
        "        print(f'symantic similarity {word1,word2}')\r\n",
        "        rem_q11.append(word1)\r\n",
        "        rem_q22.append(word2)       \r\n",
        "        break\r\n",
        "    else:\r\n",
        "      continue\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "symantic similarity ('we', 'I')\n",
            "symantic similarity ('are', 'these')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgan1ePfDo86",
        "outputId": "4bc90f18-1954-4af5-d3f7-478bef2f0388"
      },
      "source": [
        "rem_q11,rem_q22"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['we', 'are'], ['I', 'these'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6hVKUma5jlj"
      },
      "source": [
        "Just playing with word vectors\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "No3S-q9LvPwQ",
        "outputId": "0faabf3a-d816-41b3-9af5-6f6dc3864dca"
      },
      "source": [
        "test=sum(embedding[vocab.index('me')])\r\n",
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.1650524139404297"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1hpVjvUCzX5",
        "outputId": "f6a7a1db-c70c-47c6-d63f-455fdca51adc"
      },
      "source": [
        "np.dot(test,test)/(2*np.linalg.norm(test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5825262069702148"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2UC7YlgpXi8"
      },
      "source": [
        "assert np.dot(test,test)/2*np.linalg.norm(test) > 0.55     # check if it surpassses the thres2 for semantic similarity(cosine similarity) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo-seDCBRwXu"
      },
      "source": [
        "l1=len([word for word in q11 if word not in rem_q11])\r\n",
        "l2=len([word for word in q11 if word not in rem_q22])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U75vvqR6qfDe",
        "outputId": "8b505763-0122-49a3-a8db-7c6f7e8f290a"
      },
      "source": [
        "l1,l2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsofijqGFzY2"
      },
      "source": [
        "fuzzy_ratio=(len(c)+p_overlap)/(l1+l2+len(c)+len(rem_q11))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL8QvyEIaWEX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4954b6d-8a6a-4b60-b7be-57f45d59c0b2"
      },
      "source": [
        "fuzzy_ratio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.20267603]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_CuJQUrFxz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db7d78e5-c399-4b48-a0c3-b63fabef35b8"
      },
      "source": [
        "p_overlap"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.2829573]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ1MyF8K0tbT"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}