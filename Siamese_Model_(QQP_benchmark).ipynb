{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Siamese Model  (QQP benchmark)",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os-U4ChOzAZy"
      },
      "source": [
        "# Method **1**\r\n",
        "\r\n",
        "**Siamese model on benchmark dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G03Pyj1pzD-_",
        "outputId": "40eaf5c2-fbc4-4daf-8d64-7d8635cb7278"
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Dense,Input,Embedding,Bidirectional,LSTM,Lambda,Reshape\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Q73WjCafVkcH",
        "outputId": "037210fc-0ea3-4f4d-fe12-42a95a8941ef"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZQ0IUa-zlpl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "c5b12ca4-9846-4285-ef06-771423116137"
      },
      "source": [
        "# Date : 24.01.2021\r\n",
        "\r\n",
        "\r\n",
        "df=pd.read_csv('/content/drive/MyDrive/Data/quora duplicate identification/train.csv',header=0)\r\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  ...                                          question2 is_duplicate\n",
              "0   0     1  ...  What is the step by step guide to invest in sh...            0\n",
              "1   1     3  ...  What would happen if the Indian government sto...            0\n",
              "2   2     5  ...  How can Internet speed be increased by hacking...            0\n",
              "3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n",
              "4   4     9  ...            Which fish would survive in salt water?            0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVCWe0nOlyjd",
        "outputId": "a8522cc5-2eb1-4de2-f81c-3306d2ecfd79"
      },
      "source": [
        "#some exploration\r\n",
        "\r\n",
        "df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 404290 entries, 0 to 404289\n",
            "Data columns (total 6 columns):\n",
            " #   Column        Non-Null Count   Dtype \n",
            "---  ------        --------------   ----- \n",
            " 0   id            404290 non-null  int64 \n",
            " 1   qid1          404290 non-null  int64 \n",
            " 2   qid2          404290 non-null  int64 \n",
            " 3   question1     404289 non-null  object\n",
            " 4   question2     404288 non-null  object\n",
            " 5   is_duplicate  404290 non-null  int64 \n",
            "dtypes: int64(4), object(2)\n",
            "memory usage: 18.5+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgJWm6VJmIs6",
        "outputId": "bb5677d9-13cb-44d1-80a0-e913e451cd32"
      },
      "source": [
        "len(df['qid1'].unique()),len(df['qid2'].unique())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(290654, 299364)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C879lfaulIy",
        "outputId": "90b96a02-000c-40d9-da51-b499189259fe"
      },
      "source": [
        "print(f'No. of questions common in both ids {len(np.intersect1d(df.qid1.values,df.qid2.values))}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of questions common in both ids 52085\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHJooeKxu-3u",
        "outputId": "faba537a-4806-4a30-c903-d5b0acd3b6db"
      },
      "source": [
        "print(f'Therefore total no. of unique questions are {len(df.qid1.unique())+len(df.qid2.unique())-len(np.intersect1d(df.qid1.values,df.qid2.values))}')\r\n",
        "\r\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Therefore total no. of unique questions are 537933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlNzGVolv36v"
      },
      "source": [
        "df=df.dropna()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDF8F16pyAHX",
        "outputId": "cb02292e-6bbc-4e04-ab05-930ca497be1c"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 404287 entries, 0 to 404289\n",
            "Data columns (total 6 columns):\n",
            " #   Column        Non-Null Count   Dtype \n",
            "---  ------        --------------   ----- \n",
            " 0   id            404287 non-null  int64 \n",
            " 1   qid1          404287 non-null  int64 \n",
            " 2   qid2          404287 non-null  int64 \n",
            " 3   question1     404287 non-null  object\n",
            " 4   question2     404287 non-null  object\n",
            " 5   is_duplicate  404287 non-null  int64 \n",
            "dtypes: int64(4), object(2)\n",
            "memory usage: 21.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc6-9Fg9yBeX"
      },
      "source": [
        "#basic text cleanising\r\n",
        "\r\n",
        "x1=df['question1'].values\r\n",
        "x2=df['question2'].values"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vst5_Srxy2_X",
        "outputId": "45b39902-3f20-45f7-d25a-a6265294db17"
      },
      "source": [
        "x1[:10]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['What is the step by step guide to invest in share market in india?',\n",
              "       'What is the story of Kohinoor (Koh-i-Noor) Diamond?',\n",
              "       'How can I increase the speed of my internet connection while using a VPN?',\n",
              "       'Why am I mentally very lonely? How can I solve it?',\n",
              "       'Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?',\n",
              "       'Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?',\n",
              "       'Should I buy tiago?', 'How can I be a good geologist?',\n",
              "       'When do you use シ instead of し?',\n",
              "       'Motorola (company): Can I hack my Charter Motorolla DCX3400?'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9rP49h4y4fb"
      },
      "source": [
        "x1,x2=[i.lower() for i in x1],[i.lower() for i in x2]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSsagzGQ0JZy",
        "outputId": "b01bcfc8-9ec3-46e1-dbdb-81abf399f107"
      },
      "source": [
        "x1[:10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what is the step by step guide to invest in share market in india?',\n",
              " 'what is the story of kohinoor (koh-i-noor) diamond?',\n",
              " 'how can i increase the speed of my internet connection while using a vpn?',\n",
              " 'why am i mentally very lonely? how can i solve it?',\n",
              " 'which one dissolve in water quikly sugar, salt, methane and carbon di oxide?',\n",
              " 'astrology: i am a capricorn sun cap moon and cap rising...what does that say about me?',\n",
              " 'should i buy tiago?',\n",
              " 'how can i be a good geologist?',\n",
              " 'when do you use シ instead of し?',\n",
              " 'motorola (company): can i hack my charter motorolla dcx3400?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6esfh8-w0LeE"
      },
      "source": [
        "# some regex based cleaning\r\n",
        "import re\r\n",
        "\r\n",
        "def regex_clean(text):\r\n",
        "  text=re.sub(r'[^\\w\\s]', '',text)               # texts without punctuation  \\ used just in case if alpha-numeric characters has to be replaced for beteer replacements\r\n",
        "  text=re.sub(r'[^A-Za-z0-9]+', ' ', text)       # texts contains only alpha-numeric characters\r\n",
        "  text=re.sub('  ', '', text)                    # removing an extra spaces\r\n",
        "  text=re.sub('   ','',text)                     # removing two extra spaces\r\n",
        "  return text"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7hDCAm2twkV",
        "outputId": "545ba3f6-9e0a-44fb-c211-5e916575e753"
      },
      "source": [
        "#for normalized scores\r\n",
        "\r\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (53.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7VTW0fzvHqX"
      },
      "source": [
        "import spacy\r\n",
        "\r\n",
        "nlp=spacy.load(\"en_core_web_sm\")\r\n",
        "\r\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_tnecFFw1kXY",
        "outputId": "8d7f393c-6605-4845-c793-7ba0ead3b7c1"
      },
      "source": [
        "#test\r\n",
        "\"\"\"mystring='motorola (company): can i hack my charter motorolla dcx3400?'\r\n",
        "re.sub(r'[^A-Za-z0-9]+', ' ', mystring)\"\"\"\r\n",
        " "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"mystring='motorola (company): can i hack my charter motorolla dcx3400?'\\nre.sub(r'[^A-Za-z0-9]+', ' ', mystring)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScMtF27rwQJT"
      },
      "source": [
        "Unnormalized data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbSeUEjW2wcq"
      },
      "source": [
        "x1_data=[regex_clean(text) for text in x1]\r\n",
        "x2_data=[regex_clean(text) for text in x2]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf2iU_lqLYFP"
      },
      "source": [
        "y_data=tf.one_hot(df['is_duplicate'].values,2)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfEfExwoN7Xs",
        "outputId": "baad3b1e-ebfc-4e0a-d00e-5d2eb1acca7b"
      },
      "source": [
        "x1_data[:3]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what is the step by step guide to invest in share market in india',\n",
              " 'what is the story of kohinoor kohinoor diamond',\n",
              " 'how can i increase the speed of my internet connection while using a vpn']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZO825FS0KFUe",
        "outputId": "24e72ed2-61e5-4153-f229-870ad6494b6d"
      },
      "source": [
        "# contraction replacemets\r\n",
        "!pip install contractions"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.6/dist-packages (0.0.45)\n",
            "Requirement already satisfied: textsearch in /usr/local/lib/python3.6/dist-packages (from contractions) (0.0.17)\n",
            "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.2.0)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "37T-tbw5MPNc",
        "outputId": "6e3a1858-e90e-4a6b-8138-bbecaaf729c9"
      },
      "source": [
        "#Testing the package in pypi\r\n",
        "\r\n",
        "import contractions\r\n",
        "\"\"\"contractions.fix(\"i'll call you\")\"\"\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'contractions.fix(\"i\\'ll call you\")'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etzh_7VBMg7f"
      },
      "source": [
        "x1_data=[contractions.fix(data) for data in x1_data]\r\n",
        "x2_data=[contractions.fix(data) for data in x2_data]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFrjZTyOOz3x"
      },
      "source": [
        "# acronym identification and replacement\r\n",
        "\r\n",
        "# this is impossible for this task but if there is a small dataset on which fine tuning can be done then it could be useful."
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xzUOb6W_xpcN",
        "outputId": "515b9100-7abd-400c-e883-fed2f30d39f7"
      },
      "source": [
        "' '.join([str(i) for i in nlp(\"this is impossible for this task but if there is a small dataset on which fine tuning on this model can be done then it could be useful.\")])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'this is impossible for this task but if there is a small dataset on which fine tuning on this model can be done then it could be useful .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrJPbC7IwVuo"
      },
      "source": [
        "Normalized data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gL1TgJnwXuJ"
      },
      "source": [
        "n_x1_data=[' '.join([str(token.lemma_) for token in nlp(text)]) for text in x1_data[:1000]]    #lematization and singularization\r\n",
        "n_x2_data=[' '.join([str(token.lemma_) for token in nlp(text)]) for text in x2_data[:1000]]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5iMh19R5LZ3"
      },
      "source": [
        "#using tensorflow tokenizer\r\n",
        "\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGlYEne3x2Dc"
      },
      "source": [
        "tokenizer1=Tokenizer()\r\n",
        "tokenizer1.fit_on_texts(n_x1_data+n_x2_data)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUmp8E7mx57i"
      },
      "source": [
        "n_sequences=tokenizer1.texts_to_sequences(n_x1_data)\r\n",
        "n_sequences_2=tokenizer1.texts_to_sequences(n_x2_data)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqOXsi9cx-fY"
      },
      "source": [
        "n_x1_sequence_data=pad_sequences(n_sequences,maxlen=144)\r\n",
        "n_x2_sequence_data=pad_sequences(n_sequences_2,maxlen=144)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2HR9CQXyH0D"
      },
      "source": [
        "n_vocab=tokenizer1.word_index"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltVPYNGE5Ujc"
      },
      "source": [
        "Un-normalized data prepn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElA53enzTSQf"
      },
      "source": [
        "tokenizer=Tokenizer()\r\n",
        "tokenizer.fit_on_texts(x1_data+x2_data)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urPlqlPDXGUL"
      },
      "source": [
        "sequences=tokenizer.texts_to_sequences(x1_data)\r\n",
        "sequences_2=tokenizer.texts_to_sequences(x2_data)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htCJyVDYtref"
      },
      "source": [
        "x1_sequence_data=pad_sequences(sequences,maxlen=144)\r\n",
        "x2_sequence_data=pad_sequences(sequences_2,maxlen=144)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5qsXoqxWg08",
        "outputId": "af9d042e-e2ff-4674-d050-1eb8b10fb404"
      },
      "source": [
        "x1_data[:10]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what is the step by step guide to invest in share market in india',\n",
              " 'what is the story of kohinoor kohinoor diamond',\n",
              " 'how can i increase the speed of my internet connection while using a vpn',\n",
              " 'why am i mentally very lonely how can i solve it',\n",
              " 'which one dissolve in water quikly sugar salt methane and carbon di oxide',\n",
              " 'astrology i am a capricorn sun cap moon and cap risingwhat does that say about me',\n",
              " 'should i buy tiago',\n",
              " 'how can i be a good geologist',\n",
              " 'when do you use instead of ',\n",
              " 'motorola company can i hack my charter motorolla dcx3400']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uypaIFcwUiBp",
        "outputId": "68f63fcd-ad8c-437d-facb-44e759d245c6"
      },
      "source": [
        "tokenizer.word_index['capricorn']"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9959"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eriqxQGL6eRN"
      },
      "source": [
        "vocab=tokenizer.word_index"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IDt9Qs4fFde"
      },
      "source": [
        "# #lets try google embeddings according to the paper\r\n",
        "# !mkdir ~/.kaggle\r\n",
        "# !cp /content/drive/MyDrive/kaggle.json /root/.kaggle\r\n",
        "# !chmod 600 /root/.kaggle/kaggle.json\r\n",
        "# !kaggle datasets download alvations/vegetables-google-word2vec"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTZGt6afmqkF"
      },
      "source": [
        "# !unzip /content/vegetables-google-word2vec.zip"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZgf7ALVoJf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8865d014-f638-47af-da80-3ed8d951132e"
      },
      "source": [
        "embeddings=np.load('/content/word2vec.news.negative-sample.300d.npy')\r\n",
        "embeddings"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.1291504e-03, -8.9645386e-04,  3.1852722e-04, ...,\n",
              "        -1.5640259e-03, -1.2302399e-04, -8.6307526e-05],\n",
              "       [ 7.0312500e-02,  8.6914062e-02,  8.7890625e-02, ...,\n",
              "        -4.7607422e-02,  1.4465332e-02, -6.2500000e-02],\n",
              "       [-1.1779785e-02, -4.7363281e-02,  4.4677734e-02, ...,\n",
              "         7.1289062e-02, -3.4912109e-02,  2.4169922e-02],\n",
              "       ...,\n",
              "       [-1.9653320e-02, -9.0820312e-02, -1.9409180e-02, ...,\n",
              "        -1.6357422e-02, -1.3427734e-02,  4.6630859e-02],\n",
              "       [ 3.2714844e-02, -3.2226562e-02,  3.6132812e-02, ...,\n",
              "        -8.8500977e-03,  2.6977539e-02,  1.9042969e-02],\n",
              "       [ 4.5166016e-02, -4.5166016e-02, -3.9367676e-03, ...,\n",
              "         7.9589844e-02,  7.2265625e-02,  1.3000488e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v-ahZzepueR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57c99376-a17f-478a-99bc-33d0d437e834"
      },
      "source": [
        "tokens = [line.strip() for line in open('/content/word2vec.news.negative-sample.300d.txt')]\r\n",
        "embeddings[tokens.index('mobile')]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.06494141, -0.328125  , -0.20605469, -0.15234375, -0.27734375,\n",
              "        0.09912109,  0.10205078, -0.06054688,  0.10009766, -0.01965332,\n",
              "        0.04516602, -0.0088501 , -0.06542969, -0.10546875,  0.07568359,\n",
              "       -0.18066406,  0.07617188, -0.05249023, -0.18652344,  0.12890625,\n",
              "        0.14941406, -0.10253906,  0.03295898,  0.08691406, -0.03588867,\n",
              "       -0.11376953, -0.1328125 ,  0.26953125,  0.265625  , -0.09960938,\n",
              "       -0.17773438,  0.0246582 , -0.02001953, -0.07568359, -0.05175781,\n",
              "       -0.14257812, -0.07177734,  0.02563477,  0.08056641,  0.17773438,\n",
              "       -0.16992188, -0.12451172,  0.06640625,  0.12988281, -0.02697754,\n",
              "       -0.09472656, -0.12255859,  0.0534668 , -0.03442383, -0.10058594,\n",
              "        0.11962891,  0.04150391,  0.01226807, -0.06738281, -0.01867676,\n",
              "        0.18261719, -0.15039062,  0.09179688,  0.14257812,  0.15039062,\n",
              "       -0.11035156, -0.01031494, -0.18164062,  0.10449219, -0.19921875,\n",
              "        0.19726562, -0.10253906,  0.25195312,  0.00267029, -0.00650024,\n",
              "        0.01422119, -0.13085938,  0.00762939,  0.29882812, -0.12988281,\n",
              "       -0.17382812,  0.07324219,  0.24121094, -0.06884766, -0.09667969,\n",
              "       -0.03857422,  0.01477051,  0.16796875,  0.20214844,  0.17773438,\n",
              "       -0.16601562, -0.1015625 , -0.03271484, -0.29296875,  0.33984375,\n",
              "       -0.09472656, -0.14355469, -0.00921631, -0.27734375,  0.02319336,\n",
              "       -0.01721191,  0.02209473,  0.01464844,  0.27929688, -0.10400391,\n",
              "       -0.08642578, -0.18261719,  0.00500488,  0.328125  ,  0.15820312,\n",
              "        0.06640625,  0.10839844,  0.07128906,  0.10546875,  0.05761719,\n",
              "        0.05175781, -0.07519531, -0.08203125, -0.16308594,  0.04541016,\n",
              "        0.05737305, -0.01385498, -0.16015625,  0.08740234,  0.07128906,\n",
              "       -0.234375  , -0.02197266, -0.29882812,  0.17871094,  0.16113281,\n",
              "        0.12353516, -0.16796875,  0.07080078, -0.23730469,  0.05810547,\n",
              "       -0.08300781, -0.01220703, -0.15820312, -0.12451172, -0.22851562,\n",
              "        0.15136719,  0.22265625,  0.12792969, -0.12695312, -0.21191406,\n",
              "       -0.02319336, -0.1484375 ,  0.06738281,  0.31640625,  0.16894531,\n",
              "       -0.06738281,  0.08544922, -0.13574219, -0.41210938, -0.296875  ,\n",
              "        0.07861328,  0.07275391, -0.07763672, -0.10791016, -0.140625  ,\n",
              "       -0.05273438,  0.12402344, -0.109375  ,  0.13183594, -0.13867188,\n",
              "       -0.28125   , -0.16894531, -0.19921875, -0.04272461, -0.02941895,\n",
              "        0.06982422,  0.01635742, -0.15429688, -0.21582031, -0.34570312,\n",
              "        0.1015625 , -0.10351562, -0.04321289, -0.35351562, -0.12255859,\n",
              "       -0.006073  ,  0.32226562, -0.03271484, -0.26953125, -0.04882812,\n",
              "       -0.15039062, -0.12792969, -0.22851562, -0.04003906,  0.21679688,\n",
              "       -0.12695312,  0.12890625,  0.125     , -0.01550293,  0.00927734,\n",
              "       -0.00524902, -0.04052734, -0.03491211, -0.04296875, -0.10546875,\n",
              "        0.16601562, -0.07324219,  0.05566406,  0.01312256,  0.00921631,\n",
              "       -0.07177734, -0.03271484,  0.04663086,  0.02746582, -0.16699219,\n",
              "        0.06640625,  0.13476562, -0.09179688, -0.02380371, -0.14355469,\n",
              "        0.17285156,  0.17285156, -0.08544922, -0.15722656,  0.00485229,\n",
              "        0.05859375, -0.02832031, -0.23925781, -0.38671875,  0.1328125 ,\n",
              "       -0.00982666,  0.09082031, -0.06542969, -0.0390625 , -0.16601562,\n",
              "        0.11914062, -0.16796875, -0.06347656,  0.08984375, -0.34375   ,\n",
              "       -0.21484375, -0.20605469, -0.02319336, -0.11816406,  0.10009766,\n",
              "       -0.07080078, -0.05981445, -0.00120544, -0.14746094,  0.19140625,\n",
              "        0.19238281, -0.16210938,  0.05200195, -0.24902344,  0.03149414,\n",
              "       -0.01733398,  0.04492188,  0.09472656,  0.00701904, -0.10742188,\n",
              "        0.08984375,  0.03808594, -0.05151367,  0.29492188,  0.25390625,\n",
              "       -0.10693359, -0.11816406, -0.24414062, -0.12402344, -0.12695312,\n",
              "        0.03442383, -0.07275391,  0.07763672,  0.13867188,  0.02844238,\n",
              "        0.21972656, -0.06103516, -0.17089844, -0.26757812,  0.03466797,\n",
              "        0.06030273,  0.078125  , -0.14550781, -0.09570312,  0.2734375 ,\n",
              "       -0.08935547,  0.14550781,  0.02868652,  0.10009766, -0.04516602,\n",
              "       -0.08789062,  0.13671875, -0.05737305,  0.00141144, -0.33007812,\n",
              "        0.00946045,  0.06347656,  0.0402832 ,  0.04003906,  0.22070312,\n",
              "       -0.21972656,  0.02868652, -0.02600098, -0.24511719,  0.05517578,\n",
              "        0.03344727, -0.10839844, -0.02868652, -0.02697754,  0.01208496],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r14VSQ435h9A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6a7885e-2899-444c-93e0-a591b2a0e25e"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "108024"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFjbWkuP86pT"
      },
      "source": [
        "# embeddings_matrix = np.zeros((len(vocab)+1, 300));\r\n",
        "# for word, i in vocab.items():\r\n",
        "#   if word in tokens:\r\n",
        "#     embedding_vector = embeddings[tokens.index(word)];\r\n",
        "#     if embedding_vector is not None:\r\n",
        "#         embeddings_matrix[i] = embedding_vector;\r\n",
        "#   else:\r\n",
        "#     embeddings_matrix[i]=np.array([0]*300)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3L-int2FqaR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "106ae0d5-02b9-4036-ca9e-2faf9d7944d9"
      },
      "source": [
        "import pickle\r\n",
        "\r\n",
        "\"\"\"with open('embeddings.pkl','wb') as files:\r\n",
        "  pickle.dump(embeddings_matrix,files)\"\"\""
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"with open('embeddings.pkl','wb') as files:\\n  pickle.dump(embeddings_matrix,files)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZWOl_ROoaNa"
      },
      "source": [
        "with open('/content/drive/MyDrive/ML Model weights/quora/embeddings.pkl','rb') as files:\r\n",
        "  embeddings=pickle.load(files)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvbkdD6hxmXT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e561f3f-1a98-4bdc-9d5a-e315873fa4d0"
      },
      "source": [
        "embeddings.shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(108025, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lq7xwSK34jo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "732b0b9c-cae3-4baf-e648-a9f90ef47740"
      },
      "source": [
        "#model(siamese network) using functional API\r\n",
        "\r\n",
        "\"\"\"embedding_layer=Embedding(vocab_len+1,100,input_length=x_train_data_1.shape[-1])\r\n",
        "lstm=LSTM(512,dropout=0.3)\r\n",
        "\r\n",
        "s1=Input(shape=(x_train_data_1.shape[-1]))\r\n",
        "embed=embedding_layer(s1)\r\n",
        "x1=lstm(embed)\r\n",
        "\r\n",
        "s2=Input(shape=(x_train_data_1.shape[-1]))\r\n",
        "embed_1=embedding_layer(s2)\r\n",
        "y1=lstm(embed_1)\r\n",
        "\r\n",
        "#eucledian distance is not used here.i tried with simple DNN\r\n",
        "com=concatenate([x1,y1])                    \r\n",
        "com=Dropout(0.2)(com)\r\n",
        "com=BatchNormalization()(com)\r\n",
        "com=Dense(256,activation='relu')(com)\r\n",
        "com=Dropout(0.2)(com)\r\n",
        "pred=Dense(2,activation='softmax')(com)        \r\n",
        "\r\n",
        "model=Model([s1,s2],pred)\r\n",
        "\r\n",
        "model.compile(optimizer=Adam(0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\r\n",
        "model.summary()\"\"\""
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"embedding_layer=Embedding(vocab_len+1,100,input_length=x_train_data_1.shape[-1])\\nlstm=LSTM(512,dropout=0.3)\\n\\ns1=Input(shape=(x_train_data_1.shape[-1]))\\nembed=embedding_layer(s1)\\nx1=lstm(embed)\\n\\ns2=Input(shape=(x_train_data_1.shape[-1]))\\nembed_1=embedding_layer(s2)\\ny1=lstm(embed_1)\\n\\n#eucledian distance is not used here.i tried with simple DNN\\ncom=concatenate([x1,y1])                    \\ncom=Dropout(0.2)(com)\\ncom=BatchNormalization()(com)\\ncom=Dense(256,activation='relu')(com)\\ncom=Dropout(0.2)(com)\\npred=Dense(2,activation='softmax')(com)        \\n\\nmodel=Model([s1,s2],pred)\\n\\nmodel.compile(optimizer=Adam(0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\\nmodel.summary()\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJtvij-_Uoqo"
      },
      "source": [
        "# siamese model development \r\n",
        "\r\n",
        "class Model(tf.keras.Model):\r\n",
        "  \"\"\"for questions column\"\"\"\r\n",
        "  \r\n",
        "  def __init__(self,units_1,units_2,vocab,name):\r\n",
        "    super().__init__(name=f'input_network {name}')\r\n",
        "    self.input_1=tf.keras.layers.Input(shape=(units_1,),name=name)\r\n",
        "    self.embedding=tf.keras.layers.Embedding(len(vocab)+1,300,weights=[embeddings],trainable=False)\r\n",
        "    self.lstm=tf.keras.layers.LSTM(units_2, name=f'LSTM {name}')\r\n",
        "    \r\n",
        "\r\n",
        "  def call(self,inputs):\r\n",
        "    x=self.embedding(inputs)\r\n",
        "    x=self.lstm(x)\r\n",
        "\r\n",
        "\r\n",
        "    return x\r\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEghV6GIxCaU"
      },
      "source": [
        "class SiameseNetwork(tf.keras.Model):\r\n",
        "\r\n",
        "  def __init__(self,unit1,unit2,vocab):\r\n",
        "    super(SiameseNetwork,self).__init__()\r\n",
        "    self.dropout1=tf.keras.layers.Dropout(0.2,name='dropout1')\r\n",
        "    self.dropout2=tf.keras.layers.Dropout(0.2,name='dropout2')\r\n",
        "    self.f_dense=tf.keras.layers.Dense(2,activation='softmax' ,name='final_dense')\r\n",
        "    self.layer1=Model(unit1,unit2,vocab,'input1')\r\n",
        "    self.layer2=Model(unit1,unit2,vocab,'input2')\r\n",
        "\r\n",
        "  def call(self,input1,input2,training):\r\n",
        "    x1=self.layer1(input1)\r\n",
        "    x2=self.layer2(input2)\r\n",
        "    x=tf.keras.layers.concatenate([x1,x2])\r\n",
        "    x=self.dropout1(x)\r\n",
        "    x=self.dropout2(x)\r\n",
        "    x=self.f_dense(x)\r\n",
        "    return x"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIfbMQk5DaqR"
      },
      "source": [
        "epochs=50"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoKmOHjCG52u"
      },
      "source": [
        "loss_fn=tf.keras.losses.CategoricalCrossentropy(from_logits=True)\r\n",
        "optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001)\r\n",
        "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\r\n",
        "val_acc_metric = tf.keras.metrics.CategoricalAccuracy()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlJsefJ7666R"
      },
      "source": [
        "#Custom Training \r\n",
        "\r\n",
        "@tf.function\r\n",
        "def train(x1_train_data,x2_train_data,y_train_data,vocab,training=True):\r\n",
        "    # model1=Model(144,75,vocab)\r\n",
        "    # # x1=tf.keras.layers.Input(shape=(144,))\r\n",
        "    # # Initialized_m1= model1(x1,training=False) # calling build method\r\n",
        "    # model2=Model(144,75,vocab)\r\n",
        "    # # Initialized_m2= model2(x1,training=False) # calling build method\r\n",
        "    f_model=SiameseNetwork(144,75,vocab)\r\n",
        "    batches=16\r\n",
        "    for epoch in range(epochs):\r\n",
        "      \r\n",
        "      print(f\"epoch number {epoch}\")\r\n",
        "      dl=int(len(x1_train_data)/batches)\r\n",
        "      length=0\r\n",
        "      for batch in range(batches):\r\n",
        "        with tf.GradientTape() as tape:\r\n",
        "          # output_logits_1=model1(x1_train_data[length:dl+length],training=training)\r\n",
        "          # output_logits_2=model2(x2_train_data[length:dl+length],training=training)\r\n",
        "          final_logits=f_model(x1_train_data[length:dl+length],x2_train_data[length:dl+length],training=training)\r\n",
        "          loss_val=loss_fn(y_train_data[length:dl+length],final_logits)\r\n",
        "\r\n",
        "        grads=tape.gradient(loss_val,f_model.trainable_weights)\r\n",
        "        optimizer.apply_gradients(zip(grads,f_model.trainable_weights))\r\n",
        "        \r\n",
        "        train_acc_metric.update_state(y_train_data[length:dl+length], final_logits)\r\n",
        "        length+=dl\r\n",
        "        \r\n",
        "\r\n",
        "        print(f'loss value after {batch}th batch : {loss_val}\\n')\r\n",
        "        \r\n",
        "\r\n",
        "      train_acc = train_acc_metric.result()\r\n",
        "      print('\\n')\r\n",
        "      print(f'Training acc over epoch {epoch} : {train_acc}\\n\\n') \r\n",
        "      train_acc_metric.reset_states()\r\n",
        "\r\n",
        "    return f_model\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y5ab5sEBvZH"
      },
      "source": [
        "tf.config.run_functions_eagerly(True)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJAaj9pF8jxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb0076d8-d151-42d4-f9a1-953f9b3d9570"
      },
      "source": [
        "f_model=train(x1_sequence_data[:10000],x2_sequence_data[:10000],y_data[:10000],vocab,training=True) #just 10k data taken for testing\r\n",
        "\r\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch number 0\n",
            "loss value after 0th batch : 0.682925820350647\n",
            "\n",
            "loss value after 1th batch : 0.677506685256958\n",
            "\n",
            "loss value after 2th batch : 0.6725709438323975\n",
            "\n",
            "loss value after 3th batch : 0.68758624792099\n",
            "\n",
            "loss value after 4th batch : 0.6715638041496277\n",
            "\n",
            "loss value after 5th batch : 0.6712026596069336\n",
            "\n",
            "loss value after 6th batch : 0.672799289226532\n",
            "\n",
            "loss value after 7th batch : 0.682036817073822\n",
            "\n",
            "loss value after 8th batch : 0.6777960658073425\n",
            "\n",
            "loss value after 9th batch : 0.6643145680427551\n",
            "\n",
            "loss value after 10th batch : 0.6565314531326294\n",
            "\n",
            "loss value after 11th batch : 0.656547486782074\n",
            "\n",
            "loss value after 12th batch : 0.6610345244407654\n",
            "\n",
            "loss value after 13th batch : 0.6556926369667053\n",
            "\n",
            "loss value after 14th batch : 0.6622159481048584\n",
            "\n",
            "loss value after 15th batch : 0.6770159602165222\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 0 : 0.6182000041007996\n",
            "\n",
            "\n",
            "epoch number 1\n",
            "loss value after 0th batch : 0.6695804595947266\n",
            "\n",
            "loss value after 1th batch : 0.6607037782669067\n",
            "\n",
            "loss value after 2th batch : 0.650812029838562\n",
            "\n",
            "loss value after 3th batch : 0.6890595555305481\n",
            "\n",
            "loss value after 4th batch : 0.6630054116249084\n",
            "\n",
            "loss value after 5th batch : 0.6676417589187622\n",
            "\n",
            "loss value after 6th batch : 0.6629157066345215\n",
            "\n",
            "loss value after 7th batch : 0.6805766820907593\n",
            "\n",
            "loss value after 8th batch : 0.6725206971168518\n",
            "\n",
            "loss value after 9th batch : 0.6544138789176941\n",
            "\n",
            "loss value after 10th batch : 0.645361065864563\n",
            "\n",
            "loss value after 11th batch : 0.6432694792747498\n",
            "\n",
            "loss value after 12th batch : 0.6542008519172668\n",
            "\n",
            "loss value after 13th batch : 0.6520808339118958\n",
            "\n",
            "loss value after 14th batch : 0.657958447933197\n",
            "\n",
            "loss value after 15th batch : 0.6683235764503479\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 1 : 0.6288999915122986\n",
            "\n",
            "\n",
            "epoch number 2\n",
            "loss value after 0th batch : 0.6617072820663452\n",
            "\n",
            "loss value after 1th batch : 0.6538896560668945\n",
            "\n",
            "loss value after 2th batch : 0.6418788433074951\n",
            "\n",
            "loss value after 3th batch : 0.689216136932373\n",
            "\n",
            "loss value after 4th batch : 0.6574891805648804\n",
            "\n",
            "loss value after 5th batch : 0.6615980267524719\n",
            "\n",
            "loss value after 6th batch : 0.6567227840423584\n",
            "\n",
            "loss value after 7th batch : 0.675524890422821\n",
            "\n",
            "loss value after 8th batch : 0.6680641174316406\n",
            "\n",
            "loss value after 9th batch : 0.6473833918571472\n",
            "\n",
            "loss value after 10th batch : 0.6384162902832031\n",
            "\n",
            "loss value after 11th batch : 0.6433447003364563\n",
            "\n",
            "loss value after 12th batch : 0.6520485281944275\n",
            "\n",
            "loss value after 13th batch : 0.6424740552902222\n",
            "\n",
            "loss value after 14th batch : 0.651838481426239\n",
            "\n",
            "loss value after 15th batch : 0.6642167568206787\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 2 : 0.6290000081062317\n",
            "\n",
            "\n",
            "epoch number 3\n",
            "loss value after 0th batch : 0.6610750555992126\n",
            "\n",
            "loss value after 1th batch : 0.6522760987281799\n",
            "\n",
            "loss value after 2th batch : 0.642274796962738\n",
            "\n",
            "loss value after 3th batch : 0.6776551604270935\n",
            "\n",
            "loss value after 4th batch : 0.6573948860168457\n",
            "\n",
            "loss value after 5th batch : 0.6581178903579712\n",
            "\n",
            "loss value after 6th batch : 0.6530097723007202\n",
            "\n",
            "loss value after 7th batch : 0.6700437068939209\n",
            "\n",
            "loss value after 8th batch : 0.6655752658843994\n",
            "\n",
            "loss value after 9th batch : 0.6430270075798035\n",
            "\n",
            "loss value after 10th batch : 0.6319810748100281\n",
            "\n",
            "loss value after 11th batch : 0.6403862237930298\n",
            "\n",
            "loss value after 12th batch : 0.6516062617301941\n",
            "\n",
            "loss value after 13th batch : 0.6398810148239136\n",
            "\n",
            "loss value after 14th batch : 0.6443943977355957\n",
            "\n",
            "loss value after 15th batch : 0.6600639820098877\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 3 : 0.6290000081062317\n",
            "\n",
            "\n",
            "epoch number 4\n",
            "loss value after 0th batch : 0.6531941294670105\n",
            "\n",
            "loss value after 1th batch : 0.6466388702392578\n",
            "\n",
            "loss value after 2th batch : 0.6363199949264526\n",
            "\n",
            "loss value after 3th batch : 0.6756879687309265\n",
            "\n",
            "loss value after 4th batch : 0.6519386768341064\n",
            "\n",
            "loss value after 5th batch : 0.6524778604507446\n",
            "\n",
            "loss value after 6th batch : 0.6450492739677429\n",
            "\n",
            "loss value after 7th batch : 0.6612012982368469\n",
            "\n",
            "loss value after 8th batch : 0.6634393334388733\n",
            "\n",
            "loss value after 9th batch : 0.6390041708946228\n",
            "\n",
            "loss value after 10th batch : 0.6304720044136047\n",
            "\n",
            "loss value after 11th batch : 0.6351359486579895\n",
            "\n",
            "loss value after 12th batch : 0.6403535604476929\n",
            "\n",
            "loss value after 13th batch : 0.6327240467071533\n",
            "\n",
            "loss value after 14th batch : 0.6431280374526978\n",
            "\n",
            "loss value after 15th batch : 0.6546438932418823\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 4 : 0.6301000118255615\n",
            "\n",
            "\n",
            "epoch number 5\n",
            "loss value after 0th batch : 0.6491263508796692\n",
            "\n",
            "loss value after 1th batch : 0.6378515958786011\n",
            "\n",
            "loss value after 2th batch : 0.6315127611160278\n",
            "\n",
            "loss value after 3th batch : 0.6745487451553345\n",
            "\n",
            "loss value after 4th batch : 0.6520363688468933\n",
            "\n",
            "loss value after 5th batch : 0.6461895704269409\n",
            "\n",
            "loss value after 6th batch : 0.6372066140174866\n",
            "\n",
            "loss value after 7th batch : 0.66371750831604\n",
            "\n",
            "loss value after 8th batch : 0.6554742455482483\n",
            "\n",
            "loss value after 9th batch : 0.6281830668449402\n",
            "\n",
            "loss value after 10th batch : 0.6252440810203552\n",
            "\n",
            "loss value after 11th batch : 0.6312198042869568\n",
            "\n",
            "loss value after 12th batch : 0.6377707123756409\n",
            "\n",
            "loss value after 13th batch : 0.6320964097976685\n",
            "\n",
            "loss value after 14th batch : 0.6351961493492126\n",
            "\n",
            "loss value after 15th batch : 0.653920590877533\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 5 : 0.6315000057220459\n",
            "\n",
            "\n",
            "epoch number 6\n",
            "loss value after 0th batch : 0.645054280757904\n",
            "\n",
            "loss value after 1th batch : 0.6316466331481934\n",
            "\n",
            "loss value after 2th batch : 0.6254094839096069\n",
            "\n",
            "loss value after 3th batch : 0.6639860272407532\n",
            "\n",
            "loss value after 4th batch : 0.6478143334388733\n",
            "\n",
            "loss value after 5th batch : 0.6354576349258423\n",
            "\n",
            "loss value after 6th batch : 0.6367173194885254\n",
            "\n",
            "loss value after 7th batch : 0.6539775729179382\n",
            "\n",
            "loss value after 8th batch : 0.6514517068862915\n",
            "\n",
            "loss value after 9th batch : 0.6193817853927612\n",
            "\n",
            "loss value after 10th batch : 0.6138059496879578\n",
            "\n",
            "loss value after 11th batch : 0.6313162446022034\n",
            "\n",
            "loss value after 12th batch : 0.6331918239593506\n",
            "\n",
            "loss value after 13th batch : 0.6221606731414795\n",
            "\n",
            "loss value after 14th batch : 0.6307530403137207\n",
            "\n",
            "loss value after 15th batch : 0.637888491153717\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 6 : 0.635200023651123\n",
            "\n",
            "\n",
            "epoch number 7\n",
            "loss value after 0th batch : 0.6390648484230042\n",
            "\n",
            "loss value after 1th batch : 0.6244592070579529\n",
            "\n",
            "loss value after 2th batch : 0.6143781542778015\n",
            "\n",
            "loss value after 3th batch : 0.6611563563346863\n",
            "\n",
            "loss value after 4th batch : 0.6362400650978088\n",
            "\n",
            "loss value after 5th batch : 0.6266483068466187\n",
            "\n",
            "loss value after 6th batch : 0.6295329928398132\n",
            "\n",
            "loss value after 7th batch : 0.6492447853088379\n",
            "\n",
            "loss value after 8th batch : 0.6381523013114929\n",
            "\n",
            "loss value after 9th batch : 0.6126940250396729\n",
            "\n",
            "loss value after 10th batch : 0.6065714955329895\n",
            "\n",
            "loss value after 11th batch : 0.6247146725654602\n",
            "\n",
            "loss value after 12th batch : 0.616054356098175\n",
            "\n",
            "loss value after 13th batch : 0.6154182553291321\n",
            "\n",
            "loss value after 14th batch : 0.6164793372154236\n",
            "\n",
            "loss value after 15th batch : 0.6277429461479187\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 7 : 0.6419000029563904\n",
            "\n",
            "\n",
            "epoch number 8\n",
            "loss value after 0th batch : 0.6259869337081909\n",
            "\n",
            "loss value after 1th batch : 0.6128414273262024\n",
            "\n",
            "loss value after 2th batch : 0.599325954914093\n",
            "\n",
            "loss value after 3th batch : 0.6477645039558411\n",
            "\n",
            "loss value after 4th batch : 0.6349526047706604\n",
            "\n",
            "loss value after 5th batch : 0.6218019723892212\n",
            "\n",
            "loss value after 6th batch : 0.6111962199211121\n",
            "\n",
            "loss value after 7th batch : 0.6437264680862427\n",
            "\n",
            "loss value after 8th batch : 0.6382452845573425\n",
            "\n",
            "loss value after 9th batch : 0.5962172150611877\n",
            "\n",
            "loss value after 10th batch : 0.5983033180236816\n",
            "\n",
            "loss value after 11th batch : 0.6240419745445251\n",
            "\n",
            "loss value after 12th batch : 0.613534152507782\n",
            "\n",
            "loss value after 13th batch : 0.6073620319366455\n",
            "\n",
            "loss value after 14th batch : 0.6133025288581848\n",
            "\n",
            "loss value after 15th batch : 0.6261963844299316\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 8 : 0.6496999859809875\n",
            "\n",
            "\n",
            "epoch number 9\n",
            "loss value after 0th batch : 0.6144073009490967\n",
            "\n",
            "loss value after 1th batch : 0.5998193621635437\n",
            "\n",
            "loss value after 2th batch : 0.590537428855896\n",
            "\n",
            "loss value after 3th batch : 0.6373346447944641\n",
            "\n",
            "loss value after 4th batch : 0.6256481409072876\n",
            "\n",
            "loss value after 5th batch : 0.611822783946991\n",
            "\n",
            "loss value after 6th batch : 0.6012500524520874\n",
            "\n",
            "loss value after 7th batch : 0.6327420473098755\n",
            "\n",
            "loss value after 8th batch : 0.6349462270736694\n",
            "\n",
            "loss value after 9th batch : 0.5932846069335938\n",
            "\n",
            "loss value after 10th batch : 0.5957465767860413\n",
            "\n",
            "loss value after 11th batch : 0.6249395608901978\n",
            "\n",
            "loss value after 12th batch : 0.6026785373687744\n",
            "\n",
            "loss value after 13th batch : 0.6043240427970886\n",
            "\n",
            "loss value after 14th batch : 0.6017426252365112\n",
            "\n",
            "loss value after 15th batch : 0.6155083775520325\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 9 : 0.6607000231742859\n",
            "\n",
            "\n",
            "epoch number 10\n",
            "loss value after 0th batch : 0.6049553155899048\n",
            "\n",
            "loss value after 1th batch : 0.5931119322776794\n",
            "\n",
            "loss value after 2th batch : 0.5866139531135559\n",
            "\n",
            "loss value after 3th batch : 0.63419508934021\n",
            "\n",
            "loss value after 4th batch : 0.6257253885269165\n",
            "\n",
            "loss value after 5th batch : 0.5986335277557373\n",
            "\n",
            "loss value after 6th batch : 0.5957877039909363\n",
            "\n",
            "loss value after 7th batch : 0.6272786855697632\n",
            "\n",
            "loss value after 8th batch : 0.6281477808952332\n",
            "\n",
            "loss value after 9th batch : 0.5830128192901611\n",
            "\n",
            "loss value after 10th batch : 0.5927438735961914\n",
            "\n",
            "loss value after 11th batch : 0.6236162185668945\n",
            "\n",
            "loss value after 12th batch : 0.5971712470054626\n",
            "\n",
            "loss value after 13th batch : 0.5966269969940186\n",
            "\n",
            "loss value after 14th batch : 0.5928915739059448\n",
            "\n",
            "loss value after 15th batch : 0.6080694198608398\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 10 : 0.6692000031471252\n",
            "\n",
            "\n",
            "epoch number 11\n",
            "loss value after 0th batch : 0.6069298982620239\n",
            "\n",
            "loss value after 1th batch : 0.590032696723938\n",
            "\n",
            "loss value after 2th batch : 0.587311327457428\n",
            "\n",
            "loss value after 3th batch : 0.6358205676078796\n",
            "\n",
            "loss value after 4th batch : 0.6291236281394958\n",
            "\n",
            "loss value after 5th batch : 0.5957480669021606\n",
            "\n",
            "loss value after 6th batch : 0.5936031341552734\n",
            "\n",
            "loss value after 7th batch : 0.6258623600006104\n",
            "\n",
            "loss value after 8th batch : 0.6218653321266174\n",
            "\n",
            "loss value after 9th batch : 0.5775921940803528\n",
            "\n",
            "loss value after 10th batch : 0.5877135992050171\n",
            "\n",
            "loss value after 11th batch : 0.6149749755859375\n",
            "\n",
            "loss value after 12th batch : 0.5981853008270264\n",
            "\n",
            "loss value after 13th batch : 0.5948903560638428\n",
            "\n",
            "loss value after 14th batch : 0.5845242738723755\n",
            "\n",
            "loss value after 15th batch : 0.6118586659431458\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 11 : 0.6718000173568726\n",
            "\n",
            "\n",
            "epoch number 12\n",
            "loss value after 0th batch : 0.6002543568611145\n",
            "\n",
            "loss value after 1th batch : 0.5820430517196655\n",
            "\n",
            "loss value after 2th batch : 0.5826985239982605\n",
            "\n",
            "loss value after 3th batch : 0.626662015914917\n",
            "\n",
            "loss value after 4th batch : 0.6176742315292358\n",
            "\n",
            "loss value after 5th batch : 0.5906489491462708\n",
            "\n",
            "loss value after 6th batch : 0.5882619023323059\n",
            "\n",
            "loss value after 7th batch : 0.6240255236625671\n",
            "\n",
            "loss value after 8th batch : 0.6186020374298096\n",
            "\n",
            "loss value after 9th batch : 0.5749552249908447\n",
            "\n",
            "loss value after 10th batch : 0.5879891514778137\n",
            "\n",
            "loss value after 11th batch : 0.6157832145690918\n",
            "\n",
            "loss value after 12th batch : 0.5848808884620667\n",
            "\n",
            "loss value after 13th batch : 0.5956343412399292\n",
            "\n",
            "loss value after 14th batch : 0.5847197771072388\n",
            "\n",
            "loss value after 15th batch : 0.6105780005455017\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 12 : 0.6722000241279602\n",
            "\n",
            "\n",
            "epoch number 13\n",
            "loss value after 0th batch : 0.6020487546920776\n",
            "\n",
            "loss value after 1th batch : 0.5762458443641663\n",
            "\n",
            "loss value after 2th batch : 0.5791134238243103\n",
            "\n",
            "loss value after 3th batch : 0.6261622309684753\n",
            "\n",
            "loss value after 4th batch : 0.6185060739517212\n",
            "\n",
            "loss value after 5th batch : 0.5862735509872437\n",
            "\n",
            "loss value after 6th batch : 0.5836935043334961\n",
            "\n",
            "loss value after 7th batch : 0.619135856628418\n",
            "\n",
            "loss value after 8th batch : 0.6140710115432739\n",
            "\n",
            "loss value after 9th batch : 0.5735511779785156\n",
            "\n",
            "loss value after 10th batch : 0.5902413725852966\n",
            "\n",
            "loss value after 11th batch : 0.614930272102356\n",
            "\n",
            "loss value after 12th batch : 0.5892054438591003\n",
            "\n",
            "loss value after 13th batch : 0.5909453630447388\n",
            "\n",
            "loss value after 14th batch : 0.5806251168251038\n",
            "\n",
            "loss value after 15th batch : 0.6050987839698792\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 13 : 0.680400013923645\n",
            "\n",
            "\n",
            "epoch number 14\n",
            "loss value after 0th batch : 0.5949646234512329\n",
            "\n",
            "loss value after 1th batch : 0.5811443328857422\n",
            "\n",
            "loss value after 2th batch : 0.5742876529693604\n",
            "\n",
            "loss value after 3th batch : 0.6236897110939026\n",
            "\n",
            "loss value after 4th batch : 0.6106408834457397\n",
            "\n",
            "loss value after 5th batch : 0.5840258598327637\n",
            "\n",
            "loss value after 6th batch : 0.5853970646858215\n",
            "\n",
            "loss value after 7th batch : 0.6234900951385498\n",
            "\n",
            "loss value after 8th batch : 0.6085166931152344\n",
            "\n",
            "loss value after 9th batch : 0.5690580010414124\n",
            "\n",
            "loss value after 10th batch : 0.5847328305244446\n",
            "\n",
            "loss value after 11th batch : 0.6103008389472961\n",
            "\n",
            "loss value after 12th batch : 0.5810055732727051\n",
            "\n",
            "loss value after 13th batch : 0.5836320519447327\n",
            "\n",
            "loss value after 14th batch : 0.5724549889564514\n",
            "\n",
            "loss value after 15th batch : 0.6040269732475281\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 14 : 0.6825000047683716\n",
            "\n",
            "\n",
            "epoch number 15\n",
            "loss value after 0th batch : 0.5885252952575684\n",
            "\n",
            "loss value after 1th batch : 0.5763727426528931\n",
            "\n",
            "loss value after 2th batch : 0.5753151178359985\n",
            "\n",
            "loss value after 3th batch : 0.6213822364807129\n",
            "\n",
            "loss value after 4th batch : 0.6089749932289124\n",
            "\n",
            "loss value after 5th batch : 0.5834013819694519\n",
            "\n",
            "loss value after 6th batch : 0.5846513509750366\n",
            "\n",
            "loss value after 7th batch : 0.6111435294151306\n",
            "\n",
            "loss value after 8th batch : 0.6052528023719788\n",
            "\n",
            "loss value after 9th batch : 0.5693002939224243\n",
            "\n",
            "loss value after 10th batch : 0.5858575701713562\n",
            "\n",
            "loss value after 11th batch : 0.6121249198913574\n",
            "\n",
            "loss value after 12th batch : 0.573590099811554\n",
            "\n",
            "loss value after 13th batch : 0.5835311412811279\n",
            "\n",
            "loss value after 14th batch : 0.5708885788917542\n",
            "\n",
            "loss value after 15th batch : 0.6016588807106018\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 15 : 0.683899998664856\n",
            "\n",
            "\n",
            "epoch number 16\n",
            "loss value after 0th batch : 0.5923703908920288\n",
            "\n",
            "loss value after 1th batch : 0.5744733810424805\n",
            "\n",
            "loss value after 2th batch : 0.5710422396659851\n",
            "\n",
            "loss value after 3th batch : 0.6183151602745056\n",
            "\n",
            "loss value after 4th batch : 0.6086447834968567\n",
            "\n",
            "loss value after 5th batch : 0.5805714130401611\n",
            "\n",
            "loss value after 6th batch : 0.5830824375152588\n",
            "\n",
            "loss value after 7th batch : 0.6170124411582947\n",
            "\n",
            "loss value after 8th batch : 0.6128016710281372\n",
            "\n",
            "loss value after 9th batch : 0.5692929625511169\n",
            "\n",
            "loss value after 10th batch : 0.5825219750404358\n",
            "\n",
            "loss value after 11th batch : 0.6103271842002869\n",
            "\n",
            "loss value after 12th batch : 0.5732542276382446\n",
            "\n",
            "loss value after 13th batch : 0.5804310441017151\n",
            "\n",
            "loss value after 14th batch : 0.566598117351532\n",
            "\n",
            "loss value after 15th batch : 0.5989653468132019\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 16 : 0.6822999715805054\n",
            "\n",
            "\n",
            "epoch number 17\n",
            "loss value after 0th batch : 0.59208744764328\n",
            "\n",
            "loss value after 1th batch : 0.572203516960144\n",
            "\n",
            "loss value after 2th batch : 0.5713545083999634\n",
            "\n",
            "loss value after 3th batch : 0.6155915856361389\n",
            "\n",
            "loss value after 4th batch : 0.6088641881942749\n",
            "\n",
            "loss value after 5th batch : 0.5763235092163086\n",
            "\n",
            "loss value after 6th batch : 0.5793315172195435\n",
            "\n",
            "loss value after 7th batch : 0.6098589301109314\n",
            "\n",
            "loss value after 8th batch : 0.6093462109565735\n",
            "\n",
            "loss value after 9th batch : 0.5663840174674988\n",
            "\n",
            "loss value after 10th batch : 0.578253984451294\n",
            "\n",
            "loss value after 11th batch : 0.6074168682098389\n",
            "\n",
            "loss value after 12th batch : 0.5728542804718018\n",
            "\n",
            "loss value after 13th batch : 0.5830298066139221\n",
            "\n",
            "loss value after 14th batch : 0.5669161677360535\n",
            "\n",
            "loss value after 15th batch : 0.5977086424827576\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 17 : 0.6902999877929688\n",
            "\n",
            "\n",
            "epoch number 18\n",
            "loss value after 0th batch : 0.584578275680542\n",
            "\n",
            "loss value after 1th batch : 0.5719141364097595\n",
            "\n",
            "loss value after 2th batch : 0.5686978697776794\n",
            "\n",
            "loss value after 3th batch : 0.6175079345703125\n",
            "\n",
            "loss value after 4th batch : 0.6062839031219482\n",
            "\n",
            "loss value after 5th batch : 0.5842038989067078\n",
            "\n",
            "loss value after 6th batch : 0.5751197934150696\n",
            "\n",
            "loss value after 7th batch : 0.611443042755127\n",
            "\n",
            "loss value after 8th batch : 0.5985254049301147\n",
            "\n",
            "loss value after 9th batch : 0.5637447834014893\n",
            "\n",
            "loss value after 10th batch : 0.5764421224594116\n",
            "\n",
            "loss value after 11th batch : 0.6028584241867065\n",
            "\n",
            "loss value after 12th batch : 0.566962718963623\n",
            "\n",
            "loss value after 13th batch : 0.5723885297775269\n",
            "\n",
            "loss value after 14th batch : 0.5626639127731323\n",
            "\n",
            "loss value after 15th batch : 0.5925353765487671\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 18 : 0.6891000270843506\n",
            "\n",
            "\n",
            "epoch number 19\n",
            "loss value after 0th batch : 0.589752197265625\n",
            "\n",
            "loss value after 1th batch : 0.5641564726829529\n",
            "\n",
            "loss value after 2th batch : 0.5685675740242004\n",
            "\n",
            "loss value after 3th batch : 0.6153865456581116\n",
            "\n",
            "loss value after 4th batch : 0.6005366444587708\n",
            "\n",
            "loss value after 5th batch : 0.5778783559799194\n",
            "\n",
            "loss value after 6th batch : 0.5749452710151672\n",
            "\n",
            "loss value after 7th batch : 0.6073750853538513\n",
            "\n",
            "loss value after 8th batch : 0.5944439172744751\n",
            "\n",
            "loss value after 9th batch : 0.5586329102516174\n",
            "\n",
            "loss value after 10th batch : 0.5754749178886414\n",
            "\n",
            "loss value after 11th batch : 0.6059439182281494\n",
            "\n",
            "loss value after 12th batch : 0.5677086114883423\n",
            "\n",
            "loss value after 13th batch : 0.5757759213447571\n",
            "\n",
            "loss value after 14th batch : 0.5570196509361267\n",
            "\n",
            "loss value after 15th batch : 0.5953609347343445\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 19 : 0.6913999915122986\n",
            "\n",
            "\n",
            "epoch number 20\n",
            "loss value after 0th batch : 0.5861787796020508\n",
            "\n",
            "loss value after 1th batch : 0.5614785552024841\n",
            "\n",
            "loss value after 2th batch : 0.5645250678062439\n",
            "\n",
            "loss value after 3th batch : 0.6091765761375427\n",
            "\n",
            "loss value after 4th batch : 0.6105815768241882\n",
            "\n",
            "loss value after 5th batch : 0.5748734474182129\n",
            "\n",
            "loss value after 6th batch : 0.5771138668060303\n",
            "\n",
            "loss value after 7th batch : 0.6024162173271179\n",
            "\n",
            "loss value after 8th batch : 0.6034266352653503\n",
            "\n",
            "loss value after 9th batch : 0.5559198260307312\n",
            "\n",
            "loss value after 10th batch : 0.5775854587554932\n",
            "\n",
            "loss value after 11th batch : 0.6009148955345154\n",
            "\n",
            "loss value after 12th batch : 0.5654485821723938\n",
            "\n",
            "loss value after 13th batch : 0.577392578125\n",
            "\n",
            "loss value after 14th batch : 0.5577550530433655\n",
            "\n",
            "loss value after 15th batch : 0.5932523012161255\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 20 : 0.6906999945640564\n",
            "\n",
            "\n",
            "epoch number 21\n",
            "loss value after 0th batch : 0.5777943134307861\n",
            "\n",
            "loss value after 1th batch : 0.562400758266449\n",
            "\n",
            "loss value after 2th batch : 0.5665558576583862\n",
            "\n",
            "loss value after 3th batch : 0.6134585738182068\n",
            "\n",
            "loss value after 4th batch : 0.6063761711120605\n",
            "\n",
            "loss value after 5th batch : 0.5715353488922119\n",
            "\n",
            "loss value after 6th batch : 0.5729390978813171\n",
            "\n",
            "loss value after 7th batch : 0.6016204357147217\n",
            "\n",
            "loss value after 8th batch : 0.6024773716926575\n",
            "\n",
            "loss value after 9th batch : 0.5536571741104126\n",
            "\n",
            "loss value after 10th batch : 0.5715066194534302\n",
            "\n",
            "loss value after 11th batch : 0.5993565320968628\n",
            "\n",
            "loss value after 12th batch : 0.564030110836029\n",
            "\n",
            "loss value after 13th batch : 0.5717835426330566\n",
            "\n",
            "loss value after 14th batch : 0.5570526719093323\n",
            "\n",
            "loss value after 15th batch : 0.5915797352790833\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 21 : 0.6924999952316284\n",
            "\n",
            "\n",
            "epoch number 22\n",
            "loss value after 0th batch : 0.5799981355667114\n",
            "\n",
            "loss value after 1th batch : 0.5594475865364075\n",
            "\n",
            "loss value after 2th batch : 0.5643038749694824\n",
            "\n",
            "loss value after 3th batch : 0.6055833697319031\n",
            "\n",
            "loss value after 4th batch : 0.6052502989768982\n",
            "\n",
            "loss value after 5th batch : 0.5728034377098083\n",
            "\n",
            "loss value after 6th batch : 0.5746973156929016\n",
            "\n",
            "loss value after 7th batch : 0.6007529497146606\n",
            "\n",
            "loss value after 8th batch : 0.6002274751663208\n",
            "\n",
            "loss value after 9th batch : 0.5545060634613037\n",
            "\n",
            "loss value after 10th batch : 0.568005383014679\n",
            "\n",
            "loss value after 11th batch : 0.6052523255348206\n",
            "\n",
            "loss value after 12th batch : 0.5580167770385742\n",
            "\n",
            "loss value after 13th batch : 0.5704439282417297\n",
            "\n",
            "loss value after 14th batch : 0.5536030530929565\n",
            "\n",
            "loss value after 15th batch : 0.5875506401062012\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 22 : 0.6934000253677368\n",
            "\n",
            "\n",
            "epoch number 23\n",
            "loss value after 0th batch : 0.575135350227356\n",
            "\n",
            "loss value after 1th batch : 0.558207631111145\n",
            "\n",
            "loss value after 2th batch : 0.5667198896408081\n",
            "\n",
            "loss value after 3th batch : 0.607353687286377\n",
            "\n",
            "loss value after 4th batch : 0.6028924584388733\n",
            "\n",
            "loss value after 5th batch : 0.5682152509689331\n",
            "\n",
            "loss value after 6th batch : 0.5723678469657898\n",
            "\n",
            "loss value after 7th batch : 0.60126131772995\n",
            "\n",
            "loss value after 8th batch : 0.591792643070221\n",
            "\n",
            "loss value after 9th batch : 0.552185595035553\n",
            "\n",
            "loss value after 10th batch : 0.570040225982666\n",
            "\n",
            "loss value after 11th batch : 0.5953950881958008\n",
            "\n",
            "loss value after 12th batch : 0.5608165264129639\n",
            "\n",
            "loss value after 13th batch : 0.565665602684021\n",
            "\n",
            "loss value after 14th batch : 0.5499957799911499\n",
            "\n",
            "loss value after 15th batch : 0.584148645401001\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 23 : 0.6948999762535095\n",
            "\n",
            "\n",
            "epoch number 24\n",
            "loss value after 0th batch : 0.5753731727600098\n",
            "\n",
            "loss value after 1th batch : 0.5584472417831421\n",
            "\n",
            "loss value after 2th batch : 0.5643670558929443\n",
            "\n",
            "loss value after 3th batch : 0.6029648184776306\n",
            "\n",
            "loss value after 4th batch : 0.5953735709190369\n",
            "\n",
            "loss value after 5th batch : 0.5616403818130493\n",
            "\n",
            "loss value after 6th batch : 0.5673883557319641\n",
            "\n",
            "loss value after 7th batch : 0.5972005128860474\n",
            "\n",
            "loss value after 8th batch : 0.598131537437439\n",
            "\n",
            "loss value after 9th batch : 0.5464693307876587\n",
            "\n",
            "loss value after 10th batch : 0.5660626888275146\n",
            "\n",
            "loss value after 11th batch : 0.5932079553604126\n",
            "\n",
            "loss value after 12th batch : 0.5552442669868469\n",
            "\n",
            "loss value after 13th batch : 0.5618206262588501\n",
            "\n",
            "loss value after 14th batch : 0.5456560254096985\n",
            "\n",
            "loss value after 15th batch : 0.5841595530509949\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 24 : 0.6973000168800354\n",
            "\n",
            "\n",
            "epoch number 25\n",
            "loss value after 0th batch : 0.5766167044639587\n",
            "\n",
            "loss value after 1th batch : 0.5559760928153992\n",
            "\n",
            "loss value after 2th batch : 0.565006673336029\n",
            "\n",
            "loss value after 3th batch : 0.6032590866088867\n",
            "\n",
            "loss value after 4th batch : 0.5987995266914368\n",
            "\n",
            "loss value after 5th batch : 0.5680040121078491\n",
            "\n",
            "loss value after 6th batch : 0.567513108253479\n",
            "\n",
            "loss value after 7th batch : 0.5931959748268127\n",
            "\n",
            "loss value after 8th batch : 0.5891897082328796\n",
            "\n",
            "loss value after 9th batch : 0.5519546270370483\n",
            "\n",
            "loss value after 10th batch : 0.5652507543563843\n",
            "\n",
            "loss value after 11th batch : 0.5950770378112793\n",
            "\n",
            "loss value after 12th batch : 0.5504446029663086\n",
            "\n",
            "loss value after 13th batch : 0.563880443572998\n",
            "\n",
            "loss value after 14th batch : 0.5487409830093384\n",
            "\n",
            "loss value after 15th batch : 0.5793031454086304\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 25 : 0.694599986076355\n",
            "\n",
            "\n",
            "epoch number 26\n",
            "loss value after 0th batch : 0.573860228061676\n",
            "\n",
            "loss value after 1th batch : 0.5557197332382202\n",
            "\n",
            "loss value after 2th batch : 0.5579829812049866\n",
            "\n",
            "loss value after 3th batch : 0.6000996828079224\n",
            "\n",
            "loss value after 4th batch : 0.5917454957962036\n",
            "\n",
            "loss value after 5th batch : 0.559120237827301\n",
            "\n",
            "loss value after 6th batch : 0.5627937912940979\n",
            "\n",
            "loss value after 7th batch : 0.5928391218185425\n",
            "\n",
            "loss value after 8th batch : 0.5985241532325745\n",
            "\n",
            "loss value after 9th batch : 0.5509196519851685\n",
            "\n",
            "loss value after 10th batch : 0.5632237195968628\n",
            "\n",
            "loss value after 11th batch : 0.5928986072540283\n",
            "\n",
            "loss value after 12th batch : 0.5528821349143982\n",
            "\n",
            "loss value after 13th batch : 0.5631327629089355\n",
            "\n",
            "loss value after 14th batch : 0.5433104634284973\n",
            "\n",
            "loss value after 15th batch : 0.5838268399238586\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 26 : 0.6992999911308289\n",
            "\n",
            "\n",
            "epoch number 27\n",
            "loss value after 0th batch : 0.5703226327896118\n",
            "\n",
            "loss value after 1th batch : 0.554535448551178\n",
            "\n",
            "loss value after 2th batch : 0.559348464012146\n",
            "\n",
            "loss value after 3th batch : 0.595526933670044\n",
            "\n",
            "loss value after 4th batch : 0.5901718735694885\n",
            "\n",
            "loss value after 5th batch : 0.5584363341331482\n",
            "\n",
            "loss value after 6th batch : 0.5585088133811951\n",
            "\n",
            "loss value after 7th batch : 0.5899852514266968\n",
            "\n",
            "loss value after 8th batch : 0.5916147232055664\n",
            "\n",
            "loss value after 9th batch : 0.5385698080062866\n",
            "\n",
            "loss value after 10th batch : 0.5576717853546143\n",
            "\n",
            "loss value after 11th batch : 0.5905380845069885\n",
            "\n",
            "loss value after 12th batch : 0.5543105006217957\n",
            "\n",
            "loss value after 13th batch : 0.5589385032653809\n",
            "\n",
            "loss value after 14th batch : 0.5451496839523315\n",
            "\n",
            "loss value after 15th batch : 0.5807682275772095\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 27 : 0.7017999887466431\n",
            "\n",
            "\n",
            "epoch number 28\n",
            "loss value after 0th batch : 0.5672264099121094\n",
            "\n",
            "loss value after 1th batch : 0.5500381588935852\n",
            "\n",
            "loss value after 2th batch : 0.5597819089889526\n",
            "\n",
            "loss value after 3th batch : 0.5928594470024109\n",
            "\n",
            "loss value after 4th batch : 0.5891557335853577\n",
            "\n",
            "loss value after 5th batch : 0.5594427585601807\n",
            "\n",
            "loss value after 6th batch : 0.5642225742340088\n",
            "\n",
            "loss value after 7th batch : 0.5873976349830627\n",
            "\n",
            "loss value after 8th batch : 0.5946111679077148\n",
            "\n",
            "loss value after 9th batch : 0.546515941619873\n",
            "\n",
            "loss value after 10th batch : 0.5622447729110718\n",
            "\n",
            "loss value after 11th batch : 0.5861083269119263\n",
            "\n",
            "loss value after 12th batch : 0.5552109479904175\n",
            "\n",
            "loss value after 13th batch : 0.5566806197166443\n",
            "\n",
            "loss value after 14th batch : 0.539039671421051\n",
            "\n",
            "loss value after 15th batch : 0.5776075720787048\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 28 : 0.70169997215271\n",
            "\n",
            "\n",
            "epoch number 29\n",
            "loss value after 0th batch : 0.5706462264060974\n",
            "\n",
            "loss value after 1th batch : 0.550940752029419\n",
            "\n",
            "loss value after 2th batch : 0.5551794171333313\n",
            "\n",
            "loss value after 3th batch : 0.6013057827949524\n",
            "\n",
            "loss value after 4th batch : 0.5865762829780579\n",
            "\n",
            "loss value after 5th batch : 0.5629725456237793\n",
            "\n",
            "loss value after 6th batch : 0.5591723918914795\n",
            "\n",
            "loss value after 7th batch : 0.5916697978973389\n",
            "\n",
            "loss value after 8th batch : 0.5895158052444458\n",
            "\n",
            "loss value after 9th batch : 0.5397974252700806\n",
            "\n",
            "loss value after 10th batch : 0.5612700581550598\n",
            "\n",
            "loss value after 11th batch : 0.584307849407196\n",
            "\n",
            "loss value after 12th batch : 0.5483963489532471\n",
            "\n",
            "loss value after 13th batch : 0.5556194186210632\n",
            "\n",
            "loss value after 14th batch : 0.535609781742096\n",
            "\n",
            "loss value after 15th batch : 0.5772997736930847\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 29 : 0.7038999795913696\n",
            "\n",
            "\n",
            "epoch number 30\n",
            "loss value after 0th batch : 0.5681864619255066\n",
            "\n",
            "loss value after 1th batch : 0.5430428981781006\n",
            "\n",
            "loss value after 2th batch : 0.5537054538726807\n",
            "\n",
            "loss value after 3th batch : 0.5948892831802368\n",
            "\n",
            "loss value after 4th batch : 0.5838478207588196\n",
            "\n",
            "loss value after 5th batch : 0.5616321563720703\n",
            "\n",
            "loss value after 6th batch : 0.5632176399230957\n",
            "\n",
            "loss value after 7th batch : 0.5895837545394897\n",
            "\n",
            "loss value after 8th batch : 0.591236412525177\n",
            "\n",
            "loss value after 9th batch : 0.5403808951377869\n",
            "\n",
            "loss value after 10th batch : 0.5629127025604248\n",
            "\n",
            "loss value after 11th batch : 0.5813443064689636\n",
            "\n",
            "loss value after 12th batch : 0.5502434372901917\n",
            "\n",
            "loss value after 13th batch : 0.5499010682106018\n",
            "\n",
            "loss value after 14th batch : 0.5314209461212158\n",
            "\n",
            "loss value after 15th batch : 0.5754976272583008\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 30 : 0.7014999985694885\n",
            "\n",
            "\n",
            "epoch number 31\n",
            "loss value after 0th batch : 0.5645859241485596\n",
            "\n",
            "loss value after 1th batch : 0.5466982126235962\n",
            "\n",
            "loss value after 2th batch : 0.5553581118583679\n",
            "\n",
            "loss value after 3th batch : 0.5925667881965637\n",
            "\n",
            "loss value after 4th batch : 0.5791381597518921\n",
            "\n",
            "loss value after 5th batch : 0.553957998752594\n",
            "\n",
            "loss value after 6th batch : 0.5547668933868408\n",
            "\n",
            "loss value after 7th batch : 0.5852190256118774\n",
            "\n",
            "loss value after 8th batch : 0.5929179191589355\n",
            "\n",
            "loss value after 9th batch : 0.5403892993927002\n",
            "\n",
            "loss value after 10th batch : 0.5573377013206482\n",
            "\n",
            "loss value after 11th batch : 0.5731161236763\n",
            "\n",
            "loss value after 12th batch : 0.5467120409011841\n",
            "\n",
            "loss value after 13th batch : 0.5533077120780945\n",
            "\n",
            "loss value after 14th batch : 0.5282598733901978\n",
            "\n",
            "loss value after 15th batch : 0.5757634043693542\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 31 : 0.7055000066757202\n",
            "\n",
            "\n",
            "epoch number 32\n",
            "loss value after 0th batch : 0.5638936758041382\n",
            "\n",
            "loss value after 1th batch : 0.5461764931678772\n",
            "\n",
            "loss value after 2th batch : 0.5560091137886047\n",
            "\n",
            "loss value after 3th batch : 0.5928312540054321\n",
            "\n",
            "loss value after 4th batch : 0.5862506628036499\n",
            "\n",
            "loss value after 5th batch : 0.5576050877571106\n",
            "\n",
            "loss value after 6th batch : 0.5527445077896118\n",
            "\n",
            "loss value after 7th batch : 0.5895189642906189\n",
            "\n",
            "loss value after 8th batch : 0.5909560322761536\n",
            "\n",
            "loss value after 9th batch : 0.5407984852790833\n",
            "\n",
            "loss value after 10th batch : 0.5522856712341309\n",
            "\n",
            "loss value after 11th batch : 0.5811377167701721\n",
            "\n",
            "loss value after 12th batch : 0.5421521663665771\n",
            "\n",
            "loss value after 13th batch : 0.5519524216651917\n",
            "\n",
            "loss value after 14th batch : 0.5278594493865967\n",
            "\n",
            "loss value after 15th batch : 0.5740765333175659\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 32 : 0.704200029373169\n",
            "\n",
            "\n",
            "epoch number 33\n",
            "loss value after 0th batch : 0.5633350014686584\n",
            "\n",
            "loss value after 1th batch : 0.5439667701721191\n",
            "\n",
            "loss value after 2th batch : 0.5509393811225891\n",
            "\n",
            "loss value after 3th batch : 0.5929209589958191\n",
            "\n",
            "loss value after 4th batch : 0.5786323547363281\n",
            "\n",
            "loss value after 5th batch : 0.553232729434967\n",
            "\n",
            "loss value after 6th batch : 0.5523369312286377\n",
            "\n",
            "loss value after 7th batch : 0.5847809910774231\n",
            "\n",
            "loss value after 8th batch : 0.588032066822052\n",
            "\n",
            "loss value after 9th batch : 0.5341417789459229\n",
            "\n",
            "loss value after 10th batch : 0.5559532642364502\n",
            "\n",
            "loss value after 11th batch : 0.5781794190406799\n",
            "\n",
            "loss value after 12th batch : 0.5425714254379272\n",
            "\n",
            "loss value after 13th batch : 0.5432637929916382\n",
            "\n",
            "loss value after 14th batch : 0.5213966369628906\n",
            "\n",
            "loss value after 15th batch : 0.5737582445144653\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 33 : 0.7049999833106995\n",
            "\n",
            "\n",
            "epoch number 34\n",
            "loss value after 0th batch : 0.5585234761238098\n",
            "\n",
            "loss value after 1th batch : 0.5399345755577087\n",
            "\n",
            "loss value after 2th batch : 0.5531915426254272\n",
            "\n",
            "loss value after 3th batch : 0.5853295922279358\n",
            "\n",
            "loss value after 4th batch : 0.5903794169425964\n",
            "\n",
            "loss value after 5th batch : 0.557567298412323\n",
            "\n",
            "loss value after 6th batch : 0.5582423210144043\n",
            "\n",
            "loss value after 7th batch : 0.5813408493995667\n",
            "\n",
            "loss value after 8th batch : 0.5846357941627502\n",
            "\n",
            "loss value after 9th batch : 0.5371910333633423\n",
            "\n",
            "loss value after 10th batch : 0.5538124442100525\n",
            "\n",
            "loss value after 11th batch : 0.5732015371322632\n",
            "\n",
            "loss value after 12th batch : 0.5381360054016113\n",
            "\n",
            "loss value after 13th batch : 0.5508280992507935\n",
            "\n",
            "loss value after 14th batch : 0.5253810882568359\n",
            "\n",
            "loss value after 15th batch : 0.5669640898704529\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 34 : 0.708899974822998\n",
            "\n",
            "\n",
            "epoch number 35\n",
            "loss value after 0th batch : 0.5605072975158691\n",
            "\n",
            "loss value after 1th batch : 0.5334299206733704\n",
            "\n",
            "loss value after 2th batch : 0.5556276440620422\n",
            "\n",
            "loss value after 3th batch : 0.5886702537536621\n",
            "\n",
            "loss value after 4th batch : 0.5829953551292419\n",
            "\n",
            "loss value after 5th batch : 0.5491428375244141\n",
            "\n",
            "loss value after 6th batch : 0.5503876209259033\n",
            "\n",
            "loss value after 7th batch : 0.5770330429077148\n",
            "\n",
            "loss value after 8th batch : 0.5851041078567505\n",
            "\n",
            "loss value after 9th batch : 0.5326849222183228\n",
            "\n",
            "loss value after 10th batch : 0.5565431714057922\n",
            "\n",
            "loss value after 11th batch : 0.5712384581565857\n",
            "\n",
            "loss value after 12th batch : 0.5376429557800293\n",
            "\n",
            "loss value after 13th batch : 0.5440924167633057\n",
            "\n",
            "loss value after 14th batch : 0.518528401851654\n",
            "\n",
            "loss value after 15th batch : 0.573379397392273\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 35 : 0.7085999846458435\n",
            "\n",
            "\n",
            "epoch number 36\n",
            "loss value after 0th batch : 0.561639666557312\n",
            "\n",
            "loss value after 1th batch : 0.5348192453384399\n",
            "\n",
            "loss value after 2th batch : 0.5531274676322937\n",
            "\n",
            "loss value after 3th batch : 0.5812869071960449\n",
            "\n",
            "loss value after 4th batch : 0.5784426927566528\n",
            "\n",
            "loss value after 5th batch : 0.5501216053962708\n",
            "\n",
            "loss value after 6th batch : 0.5495823621749878\n",
            "\n",
            "loss value after 7th batch : 0.5815036296844482\n",
            "\n",
            "loss value after 8th batch : 0.5814688801765442\n",
            "\n",
            "loss value after 9th batch : 0.5339100360870361\n",
            "\n",
            "loss value after 10th batch : 0.5538447499275208\n",
            "\n",
            "loss value after 11th batch : 0.5699735283851624\n",
            "\n",
            "loss value after 12th batch : 0.5412982702255249\n",
            "\n",
            "loss value after 13th batch : 0.5424890518188477\n",
            "\n",
            "loss value after 14th batch : 0.5174957513809204\n",
            "\n",
            "loss value after 15th batch : 0.5693380236625671\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 36 : 0.7085000276565552\n",
            "\n",
            "\n",
            "epoch number 37\n",
            "loss value after 0th batch : 0.5551847815513611\n",
            "\n",
            "loss value after 1th batch : 0.5368996858596802\n",
            "\n",
            "loss value after 2th batch : 0.5477390885353088\n",
            "\n",
            "loss value after 3th batch : 0.5813958644866943\n",
            "\n",
            "loss value after 4th batch : 0.5736358165740967\n",
            "\n",
            "loss value after 5th batch : 0.5524552464485168\n",
            "\n",
            "loss value after 6th batch : 0.5456218719482422\n",
            "\n",
            "loss value after 7th batch : 0.5781083106994629\n",
            "\n",
            "loss value after 8th batch : 0.5877755880355835\n",
            "\n",
            "loss value after 9th batch : 0.5317049026489258\n",
            "\n",
            "loss value after 10th batch : 0.5517586469650269\n",
            "\n",
            "loss value after 11th batch : 0.572310209274292\n",
            "\n",
            "loss value after 12th batch : 0.534371018409729\n",
            "\n",
            "loss value after 13th batch : 0.5447234511375427\n",
            "\n",
            "loss value after 14th batch : 0.514224112033844\n",
            "\n",
            "loss value after 15th batch : 0.5702378153800964\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 37 : 0.7093999981880188\n",
            "\n",
            "\n",
            "epoch number 38\n",
            "loss value after 0th batch : 0.5500450730323792\n",
            "\n",
            "loss value after 1th batch : 0.5393540263175964\n",
            "\n",
            "loss value after 2th batch : 0.5456663966178894\n",
            "\n",
            "loss value after 3th batch : 0.5819884538650513\n",
            "\n",
            "loss value after 4th batch : 0.5711711049079895\n",
            "\n",
            "loss value after 5th batch : 0.5447143912315369\n",
            "\n",
            "loss value after 6th batch : 0.5468146204948425\n",
            "\n",
            "loss value after 7th batch : 0.5716031193733215\n",
            "\n",
            "loss value after 8th batch : 0.5838890671730042\n",
            "\n",
            "loss value after 9th batch : 0.5266821384429932\n",
            "\n",
            "loss value after 10th batch : 0.5513166785240173\n",
            "\n",
            "loss value after 11th batch : 0.5706393718719482\n",
            "\n",
            "loss value after 12th batch : 0.5399230122566223\n",
            "\n",
            "loss value after 13th batch : 0.5403852462768555\n",
            "\n",
            "loss value after 14th batch : 0.517225980758667\n",
            "\n",
            "loss value after 15th batch : 0.5665091872215271\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 38 : 0.7121000289916992\n",
            "\n",
            "\n",
            "epoch number 39\n",
            "loss value after 0th batch : 0.5574196577072144\n",
            "\n",
            "loss value after 1th batch : 0.5353626608848572\n",
            "\n",
            "loss value after 2th batch : 0.5462583303451538\n",
            "\n",
            "loss value after 3th batch : 0.5804271697998047\n",
            "\n",
            "loss value after 4th batch : 0.5715410709381104\n",
            "\n",
            "loss value after 5th batch : 0.5482194423675537\n",
            "\n",
            "loss value after 6th batch : 0.5505013465881348\n",
            "\n",
            "loss value after 7th batch : 0.5686355233192444\n",
            "\n",
            "loss value after 8th batch : 0.5860283970832825\n",
            "\n",
            "loss value after 9th batch : 0.5299041271209717\n",
            "\n",
            "loss value after 10th batch : 0.5494045615196228\n",
            "\n",
            "loss value after 11th batch : 0.5599357485771179\n",
            "\n",
            "loss value after 12th batch : 0.5364075303077698\n",
            "\n",
            "loss value after 13th batch : 0.5400057435035706\n",
            "\n",
            "loss value after 14th batch : 0.5131190419197083\n",
            "\n",
            "loss value after 15th batch : 0.563881516456604\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 39 : 0.7128999829292297\n",
            "\n",
            "\n",
            "epoch number 40\n",
            "loss value after 0th batch : 0.5496211647987366\n",
            "\n",
            "loss value after 1th batch : 0.5257872343063354\n",
            "\n",
            "loss value after 2th batch : 0.5422730445861816\n",
            "\n",
            "loss value after 3th batch : 0.5789355635643005\n",
            "\n",
            "loss value after 4th batch : 0.5743698477745056\n",
            "\n",
            "loss value after 5th batch : 0.5488110184669495\n",
            "\n",
            "loss value after 6th batch : 0.5465651154518127\n",
            "\n",
            "loss value after 7th batch : 0.5687454342842102\n",
            "\n",
            "loss value after 8th batch : 0.5806389451026917\n",
            "\n",
            "loss value after 9th batch : 0.5241819620132446\n",
            "\n",
            "loss value after 10th batch : 0.5438398122787476\n",
            "\n",
            "loss value after 11th batch : 0.5597559213638306\n",
            "\n",
            "loss value after 12th batch : 0.5338559150695801\n",
            "\n",
            "loss value after 13th batch : 0.5376921892166138\n",
            "\n",
            "loss value after 14th batch : 0.5122720003128052\n",
            "\n",
            "loss value after 15th batch : 0.5627687573432922\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 40 : 0.7106000185012817\n",
            "\n",
            "\n",
            "epoch number 41\n",
            "loss value after 0th batch : 0.5504707098007202\n",
            "\n",
            "loss value after 1th batch : 0.5294908285140991\n",
            "\n",
            "loss value after 2th batch : 0.5426506996154785\n",
            "\n",
            "loss value after 3th batch : 0.5775749087333679\n",
            "\n",
            "loss value after 4th batch : 0.5711134076118469\n",
            "\n",
            "loss value after 5th batch : 0.544911801815033\n",
            "\n",
            "loss value after 6th batch : 0.5418080687522888\n",
            "\n",
            "loss value after 7th batch : 0.5682963728904724\n",
            "\n",
            "loss value after 8th batch : 0.5785632729530334\n",
            "\n",
            "loss value after 9th batch : 0.5304539799690247\n",
            "\n",
            "loss value after 10th batch : 0.5453671813011169\n",
            "\n",
            "loss value after 11th batch : 0.5568855404853821\n",
            "\n",
            "loss value after 12th batch : 0.5309703350067139\n",
            "\n",
            "loss value after 13th batch : 0.535890519618988\n",
            "\n",
            "loss value after 14th batch : 0.5112149119377136\n",
            "\n",
            "loss value after 15th batch : 0.5606982707977295\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 41 : 0.7150999903678894\n",
            "\n",
            "\n",
            "epoch number 42\n",
            "loss value after 0th batch : 0.5514246821403503\n",
            "\n",
            "loss value after 1th batch : 0.5206004977226257\n",
            "\n",
            "loss value after 2th batch : 0.5430870056152344\n",
            "\n",
            "loss value after 3th batch : 0.577153205871582\n",
            "\n",
            "loss value after 4th batch : 0.5687641501426697\n",
            "\n",
            "loss value after 5th batch : 0.5400296449661255\n",
            "\n",
            "loss value after 6th batch : 0.5438967943191528\n",
            "\n",
            "loss value after 7th batch : 0.5695163011550903\n",
            "\n",
            "loss value after 8th batch : 0.580169141292572\n",
            "\n",
            "loss value after 9th batch : 0.5238549113273621\n",
            "\n",
            "loss value after 10th batch : 0.5443142056465149\n",
            "\n",
            "loss value after 11th batch : 0.5515973567962646\n",
            "\n",
            "loss value after 12th batch : 0.5330066680908203\n",
            "\n",
            "loss value after 13th batch : 0.5323813557624817\n",
            "\n",
            "loss value after 14th batch : 0.5082420706748962\n",
            "\n",
            "loss value after 15th batch : 0.5536924004554749\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 42 : 0.7179999947547913\n",
            "\n",
            "\n",
            "epoch number 43\n",
            "loss value after 0th batch : 0.5548239350318909\n",
            "\n",
            "loss value after 1th batch : 0.5214890837669373\n",
            "\n",
            "loss value after 2th batch : 0.5392044186592102\n",
            "\n",
            "loss value after 3th batch : 0.5768339037895203\n",
            "\n",
            "loss value after 4th batch : 0.5711218118667603\n",
            "\n",
            "loss value after 5th batch : 0.5416944622993469\n",
            "\n",
            "loss value after 6th batch : 0.53898024559021\n",
            "\n",
            "loss value after 7th batch : 0.5660327672958374\n",
            "\n",
            "loss value after 8th batch : 0.5744093060493469\n",
            "\n",
            "loss value after 9th batch : 0.5220260620117188\n",
            "\n",
            "loss value after 10th batch : 0.5434029698371887\n",
            "\n",
            "loss value after 11th batch : 0.5534067153930664\n",
            "\n",
            "loss value after 12th batch : 0.5330012440681458\n",
            "\n",
            "loss value after 13th batch : 0.5292019248008728\n",
            "\n",
            "loss value after 14th batch : 0.5071311593055725\n",
            "\n",
            "loss value after 15th batch : 0.5654273629188538\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 43 : 0.7167999744415283\n",
            "\n",
            "\n",
            "epoch number 44\n",
            "loss value after 0th batch : 0.5492287874221802\n",
            "\n",
            "loss value after 1th batch : 0.5291873216629028\n",
            "\n",
            "loss value after 2th batch : 0.5371413230895996\n",
            "\n",
            "loss value after 3th batch : 0.5695605874061584\n",
            "\n",
            "loss value after 4th batch : 0.5652462840080261\n",
            "\n",
            "loss value after 5th batch : 0.54402756690979\n",
            "\n",
            "loss value after 6th batch : 0.5356371402740479\n",
            "\n",
            "loss value after 7th batch : 0.5694150328636169\n",
            "\n",
            "loss value after 8th batch : 0.5821180939674377\n",
            "\n",
            "loss value after 9th batch : 0.5195925235748291\n",
            "\n",
            "loss value after 10th batch : 0.5397717952728271\n",
            "\n",
            "loss value after 11th batch : 0.5450608730316162\n",
            "\n",
            "loss value after 12th batch : 0.5287749767303467\n",
            "\n",
            "loss value after 13th batch : 0.5225650072097778\n",
            "\n",
            "loss value after 14th batch : 0.5049673914909363\n",
            "\n",
            "loss value after 15th batch : 0.5607189536094666\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 44 : 0.7192999720573425\n",
            "\n",
            "\n",
            "epoch number 45\n",
            "loss value after 0th batch : 0.5452995896339417\n",
            "\n",
            "loss value after 1th batch : 0.5267959237098694\n",
            "\n",
            "loss value after 2th batch : 0.5340458154678345\n",
            "\n",
            "loss value after 3th batch : 0.5733928680419922\n",
            "\n",
            "loss value after 4th batch : 0.5571858286857605\n",
            "\n",
            "loss value after 5th batch : 0.5379990935325623\n",
            "\n",
            "loss value after 6th batch : 0.5332794189453125\n",
            "\n",
            "loss value after 7th batch : 0.5627454519271851\n",
            "\n",
            "loss value after 8th batch : 0.5761325359344482\n",
            "\n",
            "loss value after 9th batch : 0.517693281173706\n",
            "\n",
            "loss value after 10th batch : 0.5407631993293762\n",
            "\n",
            "loss value after 11th batch : 0.5538128614425659\n",
            "\n",
            "loss value after 12th batch : 0.5328759551048279\n",
            "\n",
            "loss value after 13th batch : 0.5288501381874084\n",
            "\n",
            "loss value after 14th batch : 0.5077160596847534\n",
            "\n",
            "loss value after 15th batch : 0.5588501691818237\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 45 : 0.714900016784668\n",
            "\n",
            "\n",
            "epoch number 46\n",
            "loss value after 0th batch : 0.548001766204834\n",
            "\n",
            "loss value after 1th batch : 0.5218489766120911\n",
            "\n",
            "loss value after 2th batch : 0.5375135540962219\n",
            "\n",
            "loss value after 3th batch : 0.5733144283294678\n",
            "\n",
            "loss value after 4th batch : 0.555685818195343\n",
            "\n",
            "loss value after 5th batch : 0.5397135019302368\n",
            "\n",
            "loss value after 6th batch : 0.5377482175827026\n",
            "\n",
            "loss value after 7th batch : 0.5578727722167969\n",
            "\n",
            "loss value after 8th batch : 0.5810158252716064\n",
            "\n",
            "loss value after 9th batch : 0.5194799900054932\n",
            "\n",
            "loss value after 10th batch : 0.5390074253082275\n",
            "\n",
            "loss value after 11th batch : 0.543755829334259\n",
            "\n",
            "loss value after 12th batch : 0.5253119468688965\n",
            "\n",
            "loss value after 13th batch : 0.5303671360015869\n",
            "\n",
            "loss value after 14th batch : 0.5015356540679932\n",
            "\n",
            "loss value after 15th batch : 0.5562834143638611\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 46 : 0.7215999960899353\n",
            "\n",
            "\n",
            "epoch number 47\n",
            "loss value after 0th batch : 0.5500112771987915\n",
            "\n",
            "loss value after 1th batch : 0.5191450119018555\n",
            "\n",
            "loss value after 2th batch : 0.5373787879943848\n",
            "\n",
            "loss value after 3th batch : 0.5760263800621033\n",
            "\n",
            "loss value after 4th batch : 0.5592752695083618\n",
            "\n",
            "loss value after 5th batch : 0.5418951511383057\n",
            "\n",
            "loss value after 6th batch : 0.5319887399673462\n",
            "\n",
            "loss value after 7th batch : 0.5659249424934387\n",
            "\n",
            "loss value after 8th batch : 0.5751655101776123\n",
            "\n",
            "loss value after 9th batch : 0.5167280435562134\n",
            "\n",
            "loss value after 10th batch : 0.5381171703338623\n",
            "\n",
            "loss value after 11th batch : 0.5467162132263184\n",
            "\n",
            "loss value after 12th batch : 0.5274305939674377\n",
            "\n",
            "loss value after 13th batch : 0.525195837020874\n",
            "\n",
            "loss value after 14th batch : 0.5052564144134521\n",
            "\n",
            "loss value after 15th batch : 0.5568122863769531\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 47 : 0.7178999781608582\n",
            "\n",
            "\n",
            "epoch number 48\n",
            "loss value after 0th batch : 0.5411664843559265\n",
            "\n",
            "loss value after 1th batch : 0.5231125950813293\n",
            "\n",
            "loss value after 2th batch : 0.5292409062385559\n",
            "\n",
            "loss value after 3th batch : 0.5699802041053772\n",
            "\n",
            "loss value after 4th batch : 0.5515997409820557\n",
            "\n",
            "loss value after 5th batch : 0.5388349294662476\n",
            "\n",
            "loss value after 6th batch : 0.5270849466323853\n",
            "\n",
            "loss value after 7th batch : 0.5645942687988281\n",
            "\n",
            "loss value after 8th batch : 0.5704706907272339\n",
            "\n",
            "loss value after 9th batch : 0.5141270160675049\n",
            "\n",
            "loss value after 10th batch : 0.5356935858726501\n",
            "\n",
            "loss value after 11th batch : 0.5375059843063354\n",
            "\n",
            "loss value after 12th batch : 0.532171905040741\n",
            "\n",
            "loss value after 13th batch : 0.5280466079711914\n",
            "\n",
            "loss value after 14th batch : 0.49427977204322815\n",
            "\n",
            "loss value after 15th batch : 0.5566210746765137\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 48 : 0.7215999960899353\n",
            "\n",
            "\n",
            "epoch number 49\n",
            "loss value after 0th batch : 0.5503957271575928\n",
            "\n",
            "loss value after 1th batch : 0.522773265838623\n",
            "\n",
            "loss value after 2th batch : 0.5372090339660645\n",
            "\n",
            "loss value after 3th batch : 0.566002368927002\n",
            "\n",
            "loss value after 4th batch : 0.5579507350921631\n",
            "\n",
            "loss value after 5th batch : 0.5420334935188293\n",
            "\n",
            "loss value after 6th batch : 0.5347341299057007\n",
            "\n",
            "loss value after 7th batch : 0.5580458641052246\n",
            "\n",
            "loss value after 8th batch : 0.5751379728317261\n",
            "\n",
            "loss value after 9th batch : 0.5165501832962036\n",
            "\n",
            "loss value after 10th batch : 0.5294333696365356\n",
            "\n",
            "loss value after 11th batch : 0.5368212461471558\n",
            "\n",
            "loss value after 12th batch : 0.5180469751358032\n",
            "\n",
            "loss value after 13th batch : 0.5213311314582825\n",
            "\n",
            "loss value after 14th batch : 0.49706655740737915\n",
            "\n",
            "loss value after 15th batch : 0.5501081943511963\n",
            "\n",
            "\n",
            "\n",
            "Training acc over epoch 49 : 0.7215999960899353\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G1CU3W-IAZ8",
        "outputId": "8b4c0245-c00d-4227-d877-8a1f3a7fef03"
      },
      "source": [
        "f_model"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.SiameseNetwork at 0x7f5258b8fbe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rt3ibGN2IWYk",
        "outputId": "2222a3af-1258-4aa7-d9a9-21955911266e"
      },
      "source": [
        "f_model.summary()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"siamese_network\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dropout1 (Dropout)           multiple                  0         \n",
            "_________________________________________________________________\n",
            "dropout2 (Dropout)           multiple                  0         \n",
            "_________________________________________________________________\n",
            "final_dense (Dense)          multiple                  302       \n",
            "_________________________________________________________________\n",
            "input_network input1 (Model) multiple                  32520300  \n",
            "_________________________________________________________________\n",
            "input_network input2 (Model) multiple                  32520300  \n",
            "=================================================================\n",
            "Total params: 65,040,902\n",
            "Trainable params: 225,902\n",
            "Non-trainable params: 64,815,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bje4fgeRqmp",
        "outputId": "12d21228-72ce-48dc-ec3f-65aefaeed686"
      },
      "source": [
        "type(f_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__main__.SiameseNetwork"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd6rVRAJRwt8"
      },
      "source": [
        "y_pred=tf.argmax(f_model(x1_sequence_data[:1000],x2_sequence_data[:1000]),-1)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miR8-jkUIpkS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be5127d1-2f6c-4bb2-b263-571619f8f611"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "accuracy_score(y_true.numpy(),y_pred.numpy())"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.72"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zb5TgDrh76AL"
      },
      "source": [
        "Due to excessive memory usage couldnt train this model to give its best performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0uDZPjhIYrO"
      },
      "source": [
        "f_model.load_weights('QQP.h5')"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXrjMOts7mE_"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}